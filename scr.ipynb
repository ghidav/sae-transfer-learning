{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b)0\u001b7\u001b[?47h\u001b[1;24r\u001b[m\u001b[4l\u001b[?1h\u001b=Sun Aug 04 15:10:22 2024\n",
      "╒═════════════════════════════════════════════════════════════════════════════╕\n",
      "│ NVITOP 1.3.2       Driver Version: 530.30.02      CUDA Driver Version: 12.1 │\n",
      "├───────────────────────────────┬──────────────────────┬──────────────────────┤\n",
      "│ GPU  Name        Persistence-M│ Bus-Id        Disp.A │ Volatile Uncorr. ECC │\n",
      "│ Fan  Temp  Perf  Pwr:Usage/Cap│         Memory-Usage │ GPU-Util  Compute M. │\n",
      "╞═══════════════════════════════╪══════════════════════╪══════════════════════╡\n",
      "│\u001b[31m   0  GeForce RTX 3090    On   \u001b[0m│\u001b[31m 00000000:65:00.0 Off \u001b[0m│\u001b[31m                  N/A \u001b[0m│\n",
      "│\u001b[31m 52%   63C    P2   196W / 350W \u001b[0m│\u001b[31m  20314MiB / 24.00GiB \u001b[0m│\u001b[31m     29%      Default \u001b[0m│\n",
      "╘═══════════════════════════════╧══════════════════════╧══════════════════════╛\n",
      "\u001b[1m\u001b[36m[ CPU: █▌ 4.9%         UPTIME: 109.6 days ]\u001b[0m  \u001b[1m( Load Average:  2.07  2.39  2.55 )\u001b[0m\n",
      "\u001b[1m\u001b[35m[ MEM: ██████▊ 22.7%       USED: 55.27GiB ]\u001b[0m  \u001b[1m\u001b[34m[ SWP: ▍ 1.6%                     ]\u001b[0m\n",
      "\n",
      "╒══════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Processes:                                                 \u001b[1m\u001b[33mroot\u001b[0m\u001b[1m@\u001b[0m\u001b[1m\u001b[32m9b98c8ea692a\u001b[0m │\n",
      "│ GPU     PID      USER  GPU-MEM %SM  %CPU  %MEM  TIME  COMMAND                │\n",
      "╞══════════════════════════════════════════════════════════════════════════════╡\n",
      "│\u001b[31m   0\u001b[0m 1724311 C     N/A 20310MiB  32   N/A   N/A   N/A  \u001b[31mNo Such Process\u001b[0m        │\n",
      "╘══════════════════════════════════════════════════════════════════════════════╛\n",
      "\u001b[1m\u001b[31mERROR:\u001b[0m Failed to initialize `curses` (curs_set() returned ERR)\n"
     ]
    }
   ],
   "source": [
    "!nvitop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-70m-deduped\", device = 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokens = model.to_tokens(\"Hello, my name is\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActivationCache with keys ['hook_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_rot_q', 'blocks.1.attn.hook_rot_k', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_rot_q', 'blocks.2.attn.hook_rot_k', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_rot_q', 'blocks.3.attn.hook_rot_k', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_rot_q', 'blocks.4.attn.hook_rot_k', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_rot_q', 'blocks.5.attn.hook_rot_k', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.3.hook_mlp_out'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "\n",
    "utils.get_act_name('blocks.3.hook_mlp_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit import IOICircuit\n",
    "import json\n",
    "\n",
    "with open('tasks/ioi/cfg.json') as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "with open('tasks/ioi/names.json') as f:\n",
    "    names = json.load(f)\n",
    "\n",
    "with open('tasks/ioi/prompts.json') as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "circuit = IOICircuit(\n",
    "    model= model,\n",
    "    cfg=cfg, \n",
    "    names=names, \n",
    "    prompts=prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Then, Bella and John had lots of fun at the clinic. John gave a pillow to',\n",
       " {'IO': ' Bella',\n",
       "  'POS': 'ABB',\n",
       "  'END': 18,\n",
       "  'IO_pos': 3,\n",
       "  'S1_pos': 5,\n",
       "  'S2_pos': 14,\n",
       "  'S': ' John'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = circuit.prompts[0]\n",
    "p.text, p.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Then, John and Bella had lots of fun at the clinic. John gave a pillow to'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.generate_corrupted('POS', model).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>IO</th>\n",
       "      <th>S</th>\n",
       "      <th>POS</th>\n",
       "      <th>IO_pos</th>\n",
       "      <th>S1_pos</th>\n",
       "      <th>S1+1_pos</th>\n",
       "      <th>S2_pos</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Then, Bella and John had lots of fun at the cl...</td>\n",
       "      <td>Bella</td>\n",
       "      <td>John</td>\n",
       "      <td>ABB</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Then, Ross and Adrian were working at the jers...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>Adrian</td>\n",
       "      <td>ABB</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then, Paul and Carl had lots of fun at the man...</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Carl</td>\n",
       "      <td>ABB</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Then, Olivia and Ray had lots of fun at the ra...</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>Ray</td>\n",
       "      <td>ABB</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Then, Christopher and Noah were working at the...</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Noah</td>\n",
       "      <td>ABB</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt            IO        S  \\\n",
       "0  Then, Bella and John had lots of fun at the cl...         Bella     John   \n",
       "1  Then, Ross and Adrian were working at the jers...          Ross   Adrian   \n",
       "2  Then, Paul and Carl had lots of fun at the man...          Paul     Carl   \n",
       "3  Then, Olivia and Ray had lots of fun at the ra...        Olivia      Ray   \n",
       "4  Then, Christopher and Noah were working at the...   Christopher     Noah   \n",
       "\n",
       "   POS  IO_pos  S1_pos  S1+1_pos  S2_pos  END  \n",
       "0  ABB       3       5         6      14   18  \n",
       "1  ABB       3       5         6      12   18  \n",
       "2  ABB       3       5         6      14   18  \n",
       "3  ABB       3       5         6      14   18  \n",
       "4  ABB       3       5         6      12   18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit.create_task_df()\n",
    "circuit.task_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:15<00:00, 10.08it/s]\n"
     ]
    }
   ],
   "source": [
    "circuit.get_activations(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:19<00:00, 11.07it/s]\n"
     ]
    }
   ],
   "source": [
    "circuit.compute_supervised_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit.IO_features[' Adam']['k']['IO'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:18<00:00, 16.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "bs = 64\n",
    "\n",
    "activations = {i: [] for i in ['q', 'k', 'v', 'z']}\n",
    "for b in tqdm(range(0, len(task_df), bs)):\n",
    "    tokens = model.to_tokens(task_df.iloc[b:b+bs, 0])\n",
    "\n",
    "    positions = task_df.iloc[b:b+bs][['IO_pos', 'S1_pos', 'S1+1_pos', 'S2_pos', 'END']].values\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(tokens)\n",
    "\n",
    "    for key in activations.keys():\n",
    "        key_acts = cache.stack_activation(key) # [l b pos h dm]\n",
    "        activations[key].append(torch.cat([key_acts[:, None, i, pos] for i, pos in enumerate(positions)], dim=1))\n",
    "\n",
    "    del cache\n",
    "\n",
    "activations = {key: torch.cat(values, 1).cpu() for key, values in activations.items()} # [l N 5 h dm]\n",
    "mean_activations = {key: torch.mean(values, 1).cpu() for key, values in activations.items()} # [l 5 h dm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_dictionary(df, activations):\n",
    "    \n",
    "    io_vec = {}\n",
    "    s_vec = {}\n",
    "\n",
    "    attributes = ['IO', 'S1', 'S1+1', 'S2', 'END']\n",
    "\n",
    "    unique_io = df['IO'].unique()\n",
    "    unique_s1 = df['S1'].unique()\n",
    "\n",
    "    centered_activations = {c: activations[c] - activations[c].mean(1)[:, None] for c in ['q', 'k', 'v', 'z']}\n",
    "\n",
    "    for name in tqdm(set(unique_io) | set(unique_s1)):\n",
    "        io_vec[name] = {}\n",
    "        s_vec[name] = {}\n",
    "\n",
    "        for c in ['q', 'k', 'v', 'z']:\n",
    "            mask = torch.tensor(df['IO'] == name, dtype=torch.bool, device=activations[c].device)\n",
    "            if mask.any():\n",
    "                filtered_activations = centered_activations[c][:, mask] # [l M 5 h dm]\n",
    "                io_vec[name][c] = {a: filtered_activations[:, :, i].mean(1) for i, a in enumerate(attributes)}\n",
    "\n",
    "            mask = torch.tensor(df['S1'] == name, dtype=torch.bool, device=activations[c].device)\n",
    "            if mask.any():\n",
    "                filtered_activations = centered_activations[c][:, mask]\n",
    "                s_vec[name][c] = {a: filtered_activations[:, :, i].mean(1) for i, a in enumerate(attributes)}\n",
    "\n",
    "    # Pos\n",
    "    pos_vec = {'ABB': {}, 'BAB': {}}\n",
    "    \n",
    "    for c in ['q', 'k', 'v', 'z']:\n",
    "        for pos in [0, 1]:\n",
    "            mask = torch.tensor(df['POS'] == pos, dtype=torch.bool, device=activations[c].device)\n",
    "            if mask.any():\n",
    "                filtered_activations = centered_activations[c][:, mask]\n",
    "                pos_vec['ABB' if pos == 0 else 'BAB'][c] = {a: filtered_activations[:, :, i].mean(1) for i, a in enumerate(attributes)}\n",
    "    \n",
    "    return (io_vec, s_vec, pos_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:19<00:00, 11.27it/s]\n"
     ]
    }
   ],
   "source": [
    "f = supervised_dictionary(task_df, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 12, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0][' Richard']['q']['IO'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IOIPrompt.__init__() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m circuit\u001b[38;5;241m.\u001b[39mprompts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext, \u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_corrupted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_variable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspace/sae-transfer-learning/circuit.py:61\u001b[0m, in \u001b[0;36mIOIPrompt.generate_corrupted\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     59\u001b[0m corr_prompt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIO_pos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m s1_pos\n\u001b[1;32m     60\u001b[0m corr_prompt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1_pos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m io_pos\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[43mIOIPrompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorr_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: IOIPrompt.__init__() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "circuit.prompts[0].text, circuit.prompts[0].generate_corrupted('POS').get_variable('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Then, Bella and John had lots of fun at the clinic. John gave a pillow to', 'variables': {'IO': ' Bella', 'POS': 'ABB', 'END': 18, 'IO_pos': 3, 'S1_pos': 5, 'S2_pos': 14, 'S': ' John'}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'S1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(p)\n\u001b[0;32m----> 3\u001b[0m     p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1+1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvariables\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mS1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'S1'"
     ]
    }
   ],
   "source": [
    "for p in prompts:\n",
    "    print(p)\n",
    "    p['variables']['S1+1'] = p['variables']['S1_pos'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 28 16:24:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  | 00000000:00:07.0 Off |                  Off |\n",
      "| 30%   50C    P2              87W / 300W |  26212MiB / 49140MiB |     15%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
