{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89e9178-a52c-457c-8fd1-7b8baed88b59",
   "metadata": {},
   "source": [
    "# SAEval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88520d79-198a-4eec-87b0-c45c12ed61b7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e7d3bc-6c00-4714-8a50-44f4a0fdda0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13323/836186775.py:15: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_13323/836186775.py:16: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install git+https://github.com/jbloomAus/SAELens\n",
    "  \n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3703469e-8d68-4090-b0d5-b5352e8c2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformer_lens.utils as utils\n",
    "\n",
    "import plotly.express as px\n",
    "import tqdm\n",
    "from functools import partial\n",
    "import einops\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "update_layout_set = {\n",
    "    \"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\",\n",
    "     \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\", \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\",\n",
    "     \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\"\n",
    "}\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    if isinstance(tensor, list):\n",
    "        tensor = torch.stack(tensor)\n",
    "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
    "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
    "    if \"facet_labels\" in kwargs_pre:\n",
    "        facet_labels = kwargs_pre.pop(\"facet_labels\")\n",
    "    else:\n",
    "        facet_labels = None\n",
    "    if \"color_continuous_scale\" not in kwargs_pre:\n",
    "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0,labels={\"x\":xaxis, \"y\":yaxis}, **kwargs_pre).update_layout(**kwargs_post)\n",
    "    if facet_labels:\n",
    "        for i, label in enumerate(facet_labels):\n",
    "            fig.layout.annotations[i]['text'] = label\n",
    "\n",
    "    fig.show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, return_fig=False, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    fig = px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs)\n",
    "    if return_fig:\n",
    "        return fig\n",
    "    fig.show(renderer)\n",
    "\n",
    "from typing import List\n",
    "def show_avg_logit_diffs(x_axis: List[str], per_prompt_logit_diffs: List[torch.tensor]):\n",
    "\n",
    "\n",
    "    y_data = [per_prompt_logit_diff.mean().item() for per_prompt_logit_diff in per_prompt_logit_diffs]\n",
    "    error_y_data = [per_prompt_logit_diff.std().item() for per_prompt_logit_diff in per_prompt_logit_diffs] \n",
    "\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "        x=x_axis,\n",
    "        y=y_data,\n",
    "        error_y=dict(\n",
    "            type='data',  # specifies that the actual values are given\n",
    "            array=error_y_data,  # the magnitudes of the errors\n",
    "            visible=True  # make error bars visible\n",
    "        ),\n",
    "    )])\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(title_text=f'Logit Diff after Interventions',\n",
    "                    xaxis_title_text='Intervention',\n",
    "                    yaxis_title_text='Logit diff',\n",
    "                    plot_bgcolor='white')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9964f635-947f-4608-82f3-8aabb8f29f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa59dfd8550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/workspace/huggingface/'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else: \n",
    "    device = \"cpu\"\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e517a70-458e-4ec1-ab51-9624c4a7bb1a",
   "metadata": {},
   "source": [
    "### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c08892f3-264f-421e-a7d8-25076fc98dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import HookedSAETransformer\n",
    "\n",
    "model: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2\").to(device)\n",
    "#model.set_use_attn_in(True)\n",
    "#model.set_use_attn_result(True)\n",
    "#model.set_use_hook_mlp_in(True)\n",
    "#model.set_use_split_qkv_input(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6ae4a4db-f549-4323-8e50-8e3e945e747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tasks/ioi/task.json') as f:\n",
    "    task = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cfac22c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_prompt': 'When John and Mary went to the store, Mary gave a drink to',\n",
       " 'corr_prompt': 'When John and Mary went to the store, John gave a drink to',\n",
       " 'variables': {'IO': 'John', 'S1': 'Mary', 'S2': 'Mary', 'Pos': 'ABB'}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task['prompts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "45ca6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import re\n",
    "\n",
    "def logits_diff(logits, correct_answer, incorrect_answer):\n",
    "    correct_index = model.to_single_token(correct_answer)\n",
    "    incorrect_index = model.to_single_token(incorrect_answer)\n",
    "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
    "\n",
    "def zero_abl_hook(x, hook, pos, head):\n",
    "    x[:, pos, head] = 0\n",
    "    return x\n",
    "\n",
    "def patching_hook(x, hook, pos, head, corr):\n",
    "    x[:, pos, head] = corr[:, pos, head]\n",
    "    return x\n",
    "\n",
    "def feature_patching_hook(x, hook, pos, head, f_in, f_out):\n",
    "    x[:, pos, head] = x[:, pos, head] + f_in[None, pos, head] - f_out[None, pos, head]\n",
    "    return x\n",
    "\n",
    "class TransformerCircuit:\n",
    "    def __init__(self, model, task):\n",
    "        self.model = model\n",
    "        self.task = task\n",
    "\n",
    "    def get_node(self, node_name):\n",
    "        for node in self.task['nodes']:\n",
    "            if node['name'] == node_name:\n",
    "                return node\n",
    "        return None\n",
    "\n",
    "    def get_variable(self, variable_name):\n",
    "        for variable in self.task['variables']:\n",
    "            if variable['name'] == variable_name:\n",
    "                return variable\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    def read_variable(self, x):\n",
    "        if '+' in x:\n",
    "            offset = int(x.split('+')[-1])\n",
    "        elif '-' in x:\n",
    "            offset = int(x.split('-')[-1])\n",
    "        else:\n",
    "            offset = 0\n",
    "\n",
    "        pattern = r\"\\{([^}]*)\\}\"\n",
    "        return re.findall(pattern, x)[0], offset\n",
    "\n",
    "class IOICircuit(TransformerCircuit):\n",
    "    def __init__(self, model, cfg):\n",
    "        super().__init__(model, cfg)\n",
    "\n",
    "    def run_with_patch(self, prompt, node_names, component_name, method='zero', patches=None):\n",
    "        assert method in ['zero', 'corr', 'feature'], \"Method must be either 'zero', 'corr', 'feature'\"\n",
    "        assert component_name in ['q', 'k', 'v', 'z'], \"Method must be either 'result', 'q', 'k', 'v'\"\n",
    "        \n",
    "        io = ' '+prompt['variables']['IO']\n",
    "        s1 = ' '+prompt['variables']['S1']\n",
    "        pos = prompt['variables']['Pos']\n",
    "        pos = 0 if pos == \"ABB\" else 1\n",
    "\n",
    "        clean_prompt = prompt['clean_prompt']\n",
    "        clean_tokens = model.to_tokens(clean_prompt)\n",
    "\n",
    "        if method == 'corr':\n",
    "            corr_prompt = prompt['corr_prompt']\n",
    "            corr_tokens = model.to_tokens(corr_prompt)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _, corr_cache = self.model.run_with_cache(corr_tokens)\n",
    "        elif method == 'feature':\n",
    "            f_in = patches[0]\n",
    "            f_out = patches[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            clean_logits = self.model(clean_tokens)\n",
    "        \n",
    "        nodes = [self.get_node(node_name) for node_name in node_names]\n",
    "        hooks = []\n",
    "\n",
    "        for node in nodes:\n",
    "            if component_name in ['q', 'result']:\n",
    "                var, offset = self.read_variable(node['q'])\n",
    "            else:\n",
    "                var, offset = self.read_variable(node['kv'])\n",
    "\n",
    "            var_pos = self.get_variable(var)['position'][pos] + offset\n",
    "\n",
    "            for head in node['heads']:\n",
    "                l, h = head.split('.')\n",
    "                hook_name = utils.get_act_name(component_name, int(l))\n",
    "                \n",
    "                if method == 'zero':\n",
    "                    hook_fn = partial(zero_abl_hook, pos=var_pos, head=int(h))\n",
    "                elif method == 'corr':\n",
    "                    hook_fn = partial(patching_hook, pos=var_pos, head=int(h), corr=corr_cache[hook_name])\n",
    "                elif method == 'feature':\n",
    "                    hook_fn = partial(feature_patching_hook, pos=var_pos, head=int(h), f_in=f_in[int(l)], f_out=f_out[int(l)])\n",
    "\n",
    "                hooks.append((hook_name, hook_fn))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            patched_logits = model.run_with_hooks(clean_tokens, fwd_hooks=hooks)\n",
    "\n",
    "        return logits_diff(clean_logits, io, s1) - logits_diff(patched_logits, io, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9fe7e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_circuit = IOICircuit(model, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "cd01fe11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_prompt': 'When John and Mary went to the store, Mary gave a drink to',\n",
       " 'corr_prompt': 'When John and Mary went to the store, John gave a drink to',\n",
       " 'variables': {'IO': 'John', 'S1': 'Mary', 'S2': 'Mary', 'Pos': 'ABB'}}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task['prompts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d4836a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8055, device='cuda:0')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_circuit.run_with_patch(task['prompts'][0], ['IH'], 'q', method='corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0fecd-8128-4be7-9b4a-8a90b7cc36e1",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "64c75ae0-41bf-423c-a0e2-0ed927957dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_task_activations(prompts, bs=64):\n",
    "    activations = {i: [] for i in ['q', 'k', 'v', 'z']}\n",
    "    for b in tqdm(range(0, len(prompts), bs)):\n",
    "        tokens = model.to_tokens(prompts[b:b+bs])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens)\n",
    "\n",
    "        for key in activations.keys():\n",
    "            activations[key].append(cache.stack_activation(key))\n",
    "\n",
    "    return {key: torch.cat(values, 1) for key, values in activations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0824853c-cfc8-4a83-a892-eb5e1b885ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884b9203f25d41f0964355f47f789273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [p['clean_prompt'] for p in task['prompts']]\n",
    "activations = get_task_activations(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f5fda670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 930, 15, 12, 64])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations['k'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a11075e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "task_df = {\n",
    "    'prompt': [],\n",
    "    'IO': [],\n",
    "    'S1': [],\n",
    "    'S2': [],\n",
    "    'Pos': [],\n",
    "    'IO_pos': [],\n",
    "    'S1_pos': [],\n",
    "    'S2_pos': []\n",
    "}\n",
    "\n",
    "for i, prompt in enumerate(task['prompts']):\n",
    "    task_df['prompt'].append(prompt['clean_prompt'])\n",
    "    task_df['IO'].append(prompt['variables']['IO'])\n",
    "    task_df['S1'].append(prompt['variables']['S1'])\n",
    "    task_df['S2'].append(prompt['variables']['S2'])\n",
    "\n",
    "    pos = prompt['variables']['Pos']\n",
    "    pos = 0 if pos == \"ABB\" else 1\n",
    "    task_df['Pos'].append(pos)\n",
    "\n",
    "    io_pos = ioi_circuit.get_variable('IO')['position'][pos]\n",
    "    s1_pos = ioi_circuit.get_variable('S1')['position'][pos]\n",
    "    s2_pos = ioi_circuit.get_variable('S2')['position'][pos]\n",
    "\n",
    "    task_df['IO_pos'].append(io_pos)\n",
    "    task_df['S1_pos'].append(s1_pos)\n",
    "    task_df['S2_pos'].append(s2_pos)\n",
    "\n",
    "task_df = pd.DataFrame(task_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "dba15b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>IO</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>Pos</th>\n",
       "      <th>IO_pos</th>\n",
       "      <th>S1_pos</th>\n",
       "      <th>S2_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When John and Mary went to the store, Mary gav...</td>\n",
       "      <td>John</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Paul and John went to the store, Paul gav...</td>\n",
       "      <td>John</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Paul</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Anna and John went to the store, Anna gav...</td>\n",
       "      <td>John</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Anna</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When Mark and John went to the store, Mark gav...</td>\n",
       "      <td>John</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Mark</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When John and Lucy went to the store, Lucy gav...</td>\n",
       "      <td>John</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>When Megan and Molly went to the store, Megan ...</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Megan</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>When Ryan and Molly went to the store, Ryan ga...</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>When Julie and Molly went to the store, Julie ...</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Julie</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>When Molly and Steve went to the store, Steve ...</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Steve</td>\n",
       "      <td>Steve</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>When Aaron and Molly went to the store, Aaron ...</td>\n",
       "      <td>Molly</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>930 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt     IO     S1     S2  \\\n",
       "0    When John and Mary went to the store, Mary gav...   John   Mary   Mary   \n",
       "1    When Paul and John went to the store, Paul gav...   John   Paul   Paul   \n",
       "2    When Anna and John went to the store, Anna gav...   John   Anna   Anna   \n",
       "3    When Mark and John went to the store, Mark gav...   John   Mark   Mark   \n",
       "4    When John and Lucy went to the store, Lucy gav...   John   Lucy   Lucy   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "925  When Megan and Molly went to the store, Megan ...  Molly  Megan  Megan   \n",
       "926  When Ryan and Molly went to the store, Ryan ga...  Molly   Ryan   Ryan   \n",
       "927  When Julie and Molly went to the store, Julie ...  Molly  Julie  Julie   \n",
       "928  When Molly and Steve went to the store, Steve ...  Molly  Steve  Steve   \n",
       "929  When Aaron and Molly went to the store, Aaron ...  Molly  Aaron  Aaron   \n",
       "\n",
       "     Pos  IO_pos  S1_pos  S2_pos  \n",
       "0      0       2       4      10  \n",
       "1      1       4       2      10  \n",
       "2      1       4       2      10  \n",
       "3      1       4       2      10  \n",
       "4      0       2       4      10  \n",
       "..   ...     ...     ...     ...  \n",
       "925    1       4       2      10  \n",
       "926    1       4       2      10  \n",
       "927    1       4       2      10  \n",
       "928    0       2       4      10  \n",
       "929    1       4       2      10  \n",
       "\n",
       "[930 rows x 8 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4baa0ec2-115f-483c-9c34-dd8ced96cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = ioi_circuit.get_variable('IO')['values']\n",
    "\n",
    "def ioi_supervised_dictionary(df, activations):\n",
    "    centered_activations = activations - activations.mean(2).mean(1)[:, None, None]\n",
    "    print(centered_activations.shape)\n",
    "    \n",
    "    # IO\n",
    "    io_vec = {}\n",
    "    for name in names:\n",
    "        mask = df['IO'] == name\n",
    "        #idx = df.loc[mask].index.tolist()\n",
    "        #if len(idx) > 0:\n",
    "        #    pos = df.loc[mask, 'IO_pos'].tolist()\n",
    "        #    features = torch.cat([centered_activations[:, i, p, None] for i, p in zip(idx, pos)], 1)\n",
    "        #    io_vec[name] = features.mean(1)\n",
    "        io_vec[name] = centered_activations[:, mask].mean(1)\n",
    "\n",
    "    # S\n",
    "    s1_vec = {}\n",
    "    s2_vec = {}\n",
    "    for name in names:\n",
    "        mask = df['S1'] == name\n",
    "        #idx = df.loc[mask].index.tolist()\n",
    "        #if len(idx) > 0:\n",
    "        #    pos = df.loc[mask, 'S1_pos'].tolist()\n",
    "        #    features = torch.cat([centered_activations[:, i, p, None] for i, p in zip(idx, pos)], 1)\n",
    "        #    s1_vec[name] = features.mean(1)\n",
    "        #\n",
    "        #    pos = df.loc[mask, 'S2_pos'].tolist()\n",
    "        #    features = torch.cat([centered_activations[:, i, p, None] for i, p in zip(idx, pos)], 1)\n",
    "        #    s2_vec[name] = features.mean(1)\n",
    "        s1_vec[name] = centered_activations[:, mask].mean(1)\n",
    "        s2_vec[name] = centered_activations[:, mask].mean(1)\n",
    "\n",
    "    # Pos\n",
    "    lr = LogisticRegression(penalty=None)\n",
    "    X = centered_activations[:, :, -1]\n",
    "    y = df['Pos'].to_numpy()\n",
    "    L, N, H, *_ = X.shape\n",
    "    \n",
    "    pos_vec = []\n",
    "    #for l in range(L):\n",
    "    #    pos_vec.append([])\n",
    "    #    for h in range(H):\n",
    "    #        lr.fit(X[l, :, h].cpu().numpy(), y)\n",
    "    #        pos_vec[l].append(lr.coef_[0])\n",
    "#\n",
    "    #pos_vec = torch.tensor(pos_vec)\n",
    "\n",
    "    return (io_vec, s1_vec, s2_vec, pos_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "091fbbb8-8969-40c1-b6a8-07bff0a5319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 930, 15, 12, 64])\n"
     ]
    }
   ],
   "source": [
    "io_vec, s1_vec, s2_vec, pos_vec = ioi_supervised_dictionary(task_df, activations['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "3d3614e1-7f4b-4fc7-b654-44c1781309c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "example = task['prompts'][idx]\n",
    "io = example['variables']['IO']\n",
    "s2 = example['variables']['S2']\n",
    "\n",
    "in_patch = s2_vec[io]\n",
    "out_patch = s2_vec[s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1ee61a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['NMH', 'bNMH']\n",
    "\n",
    "f_patch = ioi_circuit.run_with_patch(example, nodes, 'q', method='feature', patches=(in_patch, out_patch))\n",
    "c_patch = ioi_circuit.run_with_patch(example, nodes, 'q', method='corr')\n",
    "z_patch = ioi_circuit.run_with_patch(example, nodes, 'q', method='zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "1545205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19946670532226562 5.596443176269531 2.8782215118408203\n"
     ]
    }
   ],
   "source": [
    "print(f_patch.item(), c_patch.item(), z_patch.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9619e9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1915, device='cuda:0')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9ec01bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6125, device='cuda:0')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1911655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
