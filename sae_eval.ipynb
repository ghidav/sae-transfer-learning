{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89e9178-a52c-457c-8fd1-7b8baed88b59",
   "metadata": {},
   "source": [
    "# SAEval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88520d79-198a-4eec-87b0-c45c12ed61b7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e7d3bc-6c00-4714-8a50-44f4a0fdda0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13323/836186775.py:15: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_13323/836186775.py:16: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install git+https://github.com/jbloomAus/SAELens\n",
    "  \n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3703469e-8d68-4090-b0d5-b5352e8c2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformer_lens.utils as utils\n",
    "\n",
    "import plotly.express as px\n",
    "import tqdm\n",
    "from functools import partial\n",
    "import einops\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "update_layout_set = {\n",
    "    \"xaxis_range\", \"yaxis_range\", \"hovermode\", \"xaxis_title\", \"yaxis_title\", \"colorbar\", \"colorscale\", \"coloraxis\",\n",
    "     \"title_x\", \"bargap\", \"bargroupgap\", \"xaxis_tickformat\", \"yaxis_tickformat\", \"title_y\", \"legend_title_text\", \"xaxis_showgrid\",\n",
    "     \"xaxis_gridwidth\", \"xaxis_gridcolor\", \"yaxis_showgrid\", \"yaxis_gridwidth\"\n",
    "}\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    if isinstance(tensor, list):\n",
    "        tensor = torch.stack(tensor)\n",
    "    kwargs_post = {k: v for k, v in kwargs.items() if k in update_layout_set}\n",
    "    kwargs_pre = {k: v for k, v in kwargs.items() if k not in update_layout_set}\n",
    "    if \"facet_labels\" in kwargs_pre:\n",
    "        facet_labels = kwargs_pre.pop(\"facet_labels\")\n",
    "    else:\n",
    "        facet_labels = None\n",
    "    if \"color_continuous_scale\" not in kwargs_pre:\n",
    "        kwargs_pre[\"color_continuous_scale\"] = \"RdBu\"\n",
    "    fig = px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0,labels={\"x\":xaxis, \"y\":yaxis}, **kwargs_pre).update_layout(**kwargs_post)\n",
    "    if facet_labels:\n",
    "        for i, label in enumerate(facet_labels):\n",
    "            fig.layout.annotations[i]['text'] = label\n",
    "\n",
    "    fig.show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, return_fig=False, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    fig = px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs)\n",
    "    if return_fig:\n",
    "        return fig\n",
    "    fig.show(renderer)\n",
    "\n",
    "from typing import List\n",
    "def show_avg_logit_diffs(x_axis: List[str], per_prompt_logit_diffs: List[torch.tensor]):\n",
    "\n",
    "\n",
    "    y_data = [per_prompt_logit_diff.mean().item() for per_prompt_logit_diff in per_prompt_logit_diffs]\n",
    "    error_y_data = [per_prompt_logit_diff.std().item() for per_prompt_logit_diff in per_prompt_logit_diffs] \n",
    "\n",
    "    fig = go.Figure(data=[go.Bar(\n",
    "        x=x_axis,\n",
    "        y=y_data,\n",
    "        error_y=dict(\n",
    "            type='data',  # specifies that the actual values are given\n",
    "            array=error_y_data,  # the magnitudes of the errors\n",
    "            visible=True  # make error bars visible\n",
    "        ),\n",
    "    )])\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(title_text=f'Logit Diff after Interventions',\n",
    "                    xaxis_title_text='Intervention',\n",
    "                    yaxis_title_text='Logit diff',\n",
    "                    plot_bgcolor='white')\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9964f635-947f-4608-82f3-8aabb8f29f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa59dfd8550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/workspace/huggingface/'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "else: \n",
    "    device = \"cpu\"\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e517a70-458e-4ec1-ab51-9624c4a7bb1a",
   "metadata": {},
   "source": [
    "### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c08892f3-264f-421e-a7d8-25076fc98dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import HookedSAETransformer\n",
    "\n",
    "model: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2\").to(device)\n",
    "#model.set_use_attn_in(True)\n",
    "#model.set_use_attn_result(True)\n",
    "#model.set_use_hook_mlp_in(True)\n",
    "#model.set_use_split_qkv_input(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6ae4a4db-f549-4323-8e50-8e3e945e747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tasks/ioi/task.json') as f:\n",
    "    task = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cfac22c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_prompt': 'When John and Mary went to the store, Mary gave a drink to',\n",
       " 'corr_prompt': 'When John and Mary went to the store, John gave a drink to',\n",
       " 'variables': {'IO': 'John', 'S1': 'Mary', 'S2': 'Mary', 'Pos': 'ABB'}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task['prompts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "45ca6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import re\n",
    "\n",
    "def logits_diff(logits, correct_answer, incorrect_answer):\n",
    "    correct_index = model.to_single_token(correct_answer)\n",
    "    incorrect_index = model.to_single_token(incorrect_answer)\n",
    "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
    "\n",
    "def zero_abl_hook(x, hook, pos, head):\n",
    "    x[:, pos, head] = 0\n",
    "    return x\n",
    "\n",
    "def patching_hook(x, hook, pos, head, corr):\n",
    "    x[:, pos, head] = corr[:, pos, head]\n",
    "    return x\n",
    "\n",
    "class TransformerCircuit:\n",
    "    def __init__(self, model, task):\n",
    "        self.model = model\n",
    "        self.task = task\n",
    "\n",
    "    def get_node(self, node_name):\n",
    "        for node in self.task['nodes']:\n",
    "            if node['name'] == node_name:\n",
    "                return node\n",
    "        return None\n",
    "\n",
    "    def get_variable(self, variable_name):\n",
    "        for variable in self.task['variables']:\n",
    "            if variable['name'] == variable_name:\n",
    "                return variable\n",
    "        return None\n",
    "\n",
    "    @classmethod\n",
    "    def read_variable(self, x):\n",
    "        if '+' in x:\n",
    "            offset = int(x.split('+')[-1])\n",
    "        elif '-' in x:\n",
    "            offset = int(x.split('-')[-1])\n",
    "        else:\n",
    "            offset = 0\n",
    "\n",
    "        pattern = r\"\\{([^}]*)\\}\"\n",
    "        return re.findall(pattern, x)[0], offset\n",
    "\n",
    "class IOICircuit(TransformerCircuit):\n",
    "    def __init__(self, model, cfg):\n",
    "        super().__init__(model, cfg)\n",
    "\n",
    "    def run_with_patch(self, prompt, node_names, component_name, method='zero'):\n",
    "        assert method in ['zero', 'corr'], \"Method must be either 'zero' or 'corr'\"\n",
    "        assert component_name in ['q', 'k', 'v', 'z'], \"Method must be either 'result', 'q', 'k', 'v'\"\n",
    "        \n",
    "        io = ' '+prompt['variables']['IO']\n",
    "        s1 = ' '+prompt['variables']['S1']\n",
    "        pos = prompt['variables']['Pos']\n",
    "        pos = 0 if pos == \"ABB\" else 1\n",
    "\n",
    "        clean_prompt = prompt['clean_prompt']\n",
    "        clean_tokens = model.to_tokens(clean_prompt)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            clean_logits = self.model(clean_tokens)\n",
    "        \n",
    "        nodes = [self.get_node(node_name) for node_name in node_names]\n",
    "\n",
    "        self.model.reset_hooks(including_permanent=True)\n",
    "\n",
    "        for node in nodes:\n",
    "            if component_name in ['q', 'result']:\n",
    "                var, offset = self.read_variable(node['q'])\n",
    "            else:\n",
    "                var, offset = self.read_variable(node['kv'])\n",
    "\n",
    "            var_pos = self.get_variable(var)['position'][pos] + offset\n",
    "\n",
    "            for head in node['heads']:\n",
    "                l, h = head.split('.')\n",
    "                hook_name = utils.get_act_name(component_name, int(l))\n",
    "                \n",
    "                if method == 'zero':\n",
    "                    hook_fn = partial(zero_abl_hook, pos=var_pos, head=int(h))\n",
    "                else:\n",
    "                    corr_prompt = prompt['corr_prompt']\n",
    "                    corr_tokens = model.to_tokens(corr_prompt)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        _, corr_cache = self.model.run_with_cache(corr_tokens)\n",
    "\n",
    "                    hook_fn = partial(patching_hook, pos=var_pos, head=int(h), corr=corr_cache[hook_name])\n",
    "\n",
    "                print(hook_name, int(h))\n",
    "                self.model.add_perma_hook(hook_name, hook_fn)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            patched_logits = model(clean_tokens)\n",
    "\n",
    "        self.model.reset_hooks(including_permanent=True)\n",
    "\n",
    "        return logits_diff(clean_logits, io, s1) - logits_diff(patched_logits, io, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9fe7e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_circuit = IOICircuit(model, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d4836a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.9.attn.hook_k 6\n",
      "blocks.9.attn.hook_k 9\n",
      "blocks.10.attn.hook_k 0\n",
      "blocks.0.attn.hook_k 1\n",
      "blocks.3.attn.hook_k 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.hook_k 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_circuit.run_with_patch(task['prompts'][0], ['NMH', 'bNMH'], 'k', method='corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0fecd-8128-4be7-9b4a-8a90b7cc36e1",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64c75ae0-41bf-423c-a0e2-0ed927957dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def get_task_activations(task, bs=64):\n",
    "    activations = []\n",
    "    for b in tqdm(range(0, len(task), bs)):\n",
    "        prompts = task['prompt'].iloc[b:b+bs]\n",
    "        tokens = model.to_tokens(prompts.tolist())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens)\n",
    "\n",
    "        activations.append(cache.stack_activation('resid_post'))\n",
    "\n",
    "    return torch.cat(activations, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0824853c-cfc8-4a83-a892-eb5e1b885ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b76dddfde6e4d07b2f767ab8e2c62a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "activations = get_task_activations(ioi_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4baa0ec2-115f-483c-9c34-dd8ced96cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ioi_supervised_dictionary(task, activations):\n",
    "    l, n, p, dm = activations.shape\n",
    "    centered_activations = activations - activations.mean(2).mean(1)[:, None, None]\n",
    "    # IO\n",
    "    io_vec = {}\n",
    "    for name in names:\n",
    "        mask = task['io'] == ' '+name\n",
    "        pos = torch.tensor(task.loc[mask, 'io_pos'].tolist(), device=device)\n",
    "        features = centered_activations[:, mask].gather(2, pos[None, :, None, None].expand(l, len(pos), 1, dm))\n",
    "        io_vec[name] = features.mean(1)[:, 0]\n",
    "\n",
    "    # S1\n",
    "    s1_vec = {}\n",
    "    s2_vec = {}\n",
    "    for name in names:\n",
    "        mask = task['s'] == ' '+name\n",
    "        \n",
    "        pos = torch.tensor(task.loc[mask, 's1_pos'].tolist(), device=device)\n",
    "        features = centered_activations[:, mask].gather(2, pos[None, :, None, None].expand(l, len(pos), 1, dm))\n",
    "        s1_vec[name] = features.mean(1)[:, 0]\n",
    "    \n",
    "        pos = torch.tensor(task.loc[mask, 's2_pos'].tolist(), device=device)\n",
    "        features = centered_activations[:, mask].gather(2, pos[None, :, None, None].expand(l, len(pos), 1, dm))\n",
    "        s2_vec[name] = features.mean(1)[:, 0]\n",
    "\n",
    "    # Pos\n",
    "    X = centered_activations[:, :, -1]\n",
    "    y = torch.tensor(task['pos'] == 'ABB', device=device)\n",
    "    print(X.shape)\n",
    "    pos_vec = torch.linalg.lstsq(X, y.type(torch.float32)[None])\n",
    "\n",
    "    return (io_vec, s1_vec, s2_vec, pos_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "091fbbb8-8969-40c1-b6a8-07bff0a5319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1024, 15, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.linalg.lstsq: input.dim() must be greater or equal to other.dim() and (input.dim() - other.dim()) <= 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mioi_supervised_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mioi_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[149], line 30\u001b[0m, in \u001b[0;36mioi_supervised_dictionary\u001b[0;34m(task, activations)\u001b[0m\n\u001b[1;32m     28\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(task[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABB\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 30\u001b[0m pos_vec \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (io_vec, s1_vec, s2_vec, pos_vec)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.linalg.lstsq: input.dim() must be greater or equal to other.dim() and (input.dim() - other.dim()) <= 1"
     ]
    }
   ],
   "source": [
    "ioi_supervised_dictionary(ioi_task, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c88e6a59-48dc-4abe-88b8-dc59f8f32f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9642a0f-5f9a-46f0-928d-28655915b586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>io</th>\n",
       "      <th>s</th>\n",
       "      <th>pos</th>\n",
       "      <th>io_pos</th>\n",
       "      <th>s1_pos</th>\n",
       "      <th>s2_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When Paul and Nancy went to the store, Paul ga...</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>Paul</td>\n",
       "      <td>BAB</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Henry and Lucy went to the store, Lucy ga...</td>\n",
       "      <td>Henry</td>\n",
       "      <td>Lucy</td>\n",
       "      <td>ABB</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Aaron and Maria went to the store, Maria ...</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Maria</td>\n",
       "      <td>ABB</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When Megan and Chloe went to the store, Chloe ...</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>ABB</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When Maria and Sara went to the store, Maria g...</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Maria</td>\n",
       "      <td>BAB</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>When Linda and Diane went to the store, Linda ...</td>\n",
       "      <td>Diane</td>\n",
       "      <td>Linda</td>\n",
       "      <td>BAB</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>When Grace and Susan went to the store, Susan ...</td>\n",
       "      <td>Grace</td>\n",
       "      <td>Susan</td>\n",
       "      <td>ABB</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>When Maria and Olivia went to the store, Olivi...</td>\n",
       "      <td>Maria</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>ABB</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>When Julie and Amber went to the store, Julie ...</td>\n",
       "      <td>Amber</td>\n",
       "      <td>Julie</td>\n",
       "      <td>BAB</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>When Lisa and Holly went to the store, Holly g...</td>\n",
       "      <td>Lisa</td>\n",
       "      <td>Holly</td>\n",
       "      <td>ABB</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt      io        s  pos  \\\n",
       "0     When Paul and Nancy went to the store, Paul ga...   Nancy     Paul  BAB   \n",
       "1     When Henry and Lucy went to the store, Lucy ga...   Henry     Lucy  ABB   \n",
       "2     When Aaron and Maria went to the store, Maria ...   Aaron    Maria  ABB   \n",
       "3     When Megan and Chloe went to the store, Chloe ...   Megan    Chloe  ABB   \n",
       "4     When Maria and Sara went to the store, Maria g...    Sara    Maria  BAB   \n",
       "...                                                 ...     ...      ...  ...   \n",
       "1019  When Linda and Diane went to the store, Linda ...   Diane    Linda  BAB   \n",
       "1020  When Grace and Susan went to the store, Susan ...   Grace    Susan  ABB   \n",
       "1021  When Maria and Olivia went to the store, Olivi...   Maria   Olivia  ABB   \n",
       "1022  When Julie and Amber went to the store, Julie ...   Amber    Julie  BAB   \n",
       "1023  When Lisa and Holly went to the store, Holly g...    Lisa    Holly  ABB   \n",
       "\n",
       "      io_pos  s1_pos  s2_pos  \n",
       "0          4       2      10  \n",
       "1          2       4      10  \n",
       "2          2       4      10  \n",
       "3          2       4      10  \n",
       "4          4       2      10  \n",
       "...      ...     ...     ...  \n",
       "1019       4       2      10  \n",
       "1020       2       4      10  \n",
       "1021       2       4      10  \n",
       "1022       4       2      10  \n",
       "1023       2       4      10  \n",
       "\n",
       "[1024 rows x 7 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3614e1-7f4b-4fc7-b654-44c1781309c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
