{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, ActivationsStore, LanguageModelSAERunnerConfig\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "palette = sns.color_palette('flare', as_cmap=False, n_colors=10)\n",
    "palette_duo = [palette[0], palette[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"pythia-160m-deduped\",\n",
    "    hook_name=None,\n",
    "    hook_layer=None,\n",
    "    dataset_path=\"NeelNanda/pile-small-tokenized-2b\",\n",
    "    is_dataset_tokenized=True,\n",
    "    context_size=1024,\n",
    "    streaming=True,\n",
    "    # SAE Parameters\n",
    "    architecture=\"jumprelu\",\n",
    "    d_in=768,\n",
    "    d_sae=None,\n",
    "    b_dec_init_method=\"zeros\",\n",
    "    expansion_factor=8,\n",
    "    activation_fn=\"relu\",  # relu, tanh-relu, topk\n",
    "    normalize_sae_decoder=True,\n",
    "    from_pretrained_path=None,\n",
    "    apply_b_dec_to_input=False,\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=128,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    dtype=\"float32\",\n",
    "    prepend_bos=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-160m-deduped\", device = device)\n",
    "\n",
    "direction = \"backward\"\n",
    "ckpt_step = \"500M\"\n",
    "sae_idx = 8\n",
    "transfer = True\n",
    "\n",
    "SAE_PATH = \"/workspace/huggingface/hub/models--mech-interp--pythia-160m-deduped-rs-post/snapshots/49befceb8d1f7be1d4b3c6bef477c4e899def430\"\n",
    "\n",
    "#FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{sae_idx}\", ckpt_step)\n",
    "#BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{sae_idx}\", ckpt_step)\n",
    "#BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{sae_idx}\")\n",
    "\n",
    "#fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "#bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "#base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_store = ActivationsStore.from_config(model, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_flatten(nested_list):\n",
    "    return [x for y in nested_list for x in y]\n",
    "\n",
    "# A very handy function Neel wrote to get context around a feature activation\n",
    "def make_token_df(tokens, len_prefix=5, len_suffix=3, model = model):\n",
    "    str_tokens = [model.to_str_tokens(t) for t in tokens]\n",
    "    unique_token = [[f\"{s}/{i}\" for i, s in enumerate(str_tok)] for str_tok in str_tokens]\n",
    "    \n",
    "    context = []\n",
    "    prompt = []\n",
    "    pos = []\n",
    "    label = []\n",
    "    for b in range(tokens.shape[0]):\n",
    "        for p in range(tokens.shape[1]):\n",
    "            prefix = \"\".join(str_tokens[b][max(0, p-len_prefix):p])\n",
    "            if p==tokens.shape[1]-1:\n",
    "                suffix = \"\"\n",
    "            else:\n",
    "                suffix = \"\".join(str_tokens[b][p+1:min(tokens.shape[1]-1, p+1+len_suffix)])\n",
    "            current = str_tokens[b][p]\n",
    "            context.append(f\"{prefix}|{current}|{suffix}\")\n",
    "            prompt.append(b)\n",
    "            pos.append(p)\n",
    "            label.append(f\"{b}/{p}\")\n",
    "    # print(len(batch), len(pos), len(context), len(label))\n",
    "    return pd.DataFrame(dict(\n",
    "        str_tokens=list_flatten(str_tokens),\n",
    "        unique_token=list_flatten(unique_token),\n",
    "        context=context,\n",
    "        prompt=prompt,\n",
    "        pos=pos,\n",
    "        label=label,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding max activating examples is a bit harder. To do this we need to calculate feature activations for a large number of tokens\n",
    "feature_list = torch.randint(0, sae.cfg.d_sae, (32,))\n",
    "examples_found = 0\n",
    "all_fired_tokens = []\n",
    "all_feature_acts = []\n",
    "all_reconstructions = []\n",
    "all_token_dfs = []\n",
    "\n",
    "total_batches = 32\n",
    "batch_size_prompts = activation_store.store_batch_size_prompts\n",
    "batch_size_tokens = activation_store.context_size * batch_size_prompts\n",
    "pbar = tqdm(range(total_batches))\n",
    "for i in pbar:\n",
    "    tokens = activation_store.get_batch_tokens()\n",
    "    tokens_df = make_token_df(tokens)\n",
    "    tokens_df[\"batch\"] = i\n",
    "    \n",
    "    flat_tokens = tokens.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(tokens, stop_at_layer = sae.cfg.hook_layer + 1, names_filter = [sae.cfg.hook_name])\n",
    "        sae_in = cache[sae.cfg.hook_name]\n",
    "        feature_acts = sae.encode(sae_in).squeeze()\n",
    "\n",
    "        feature_acts = feature_acts.flatten(0,1)\n",
    "        fired_mask = (feature_acts[:, feature_list]).sum(dim=-1) > 0\n",
    "        fired_tokens = model.to_str_tokens(flat_tokens[fired_mask])\n",
    "        reconstruction = feature_acts[fired_mask][:, feature_list] @ sae.W_dec[feature_list]\n",
    "\n",
    "    token_df = tokens_df.iloc[fired_mask.cpu().nonzero().flatten().numpy()]\n",
    "    all_token_dfs.append(token_df)\n",
    "    all_feature_acts.append(feature_acts[fired_mask][:, feature_list])\n",
    "    all_fired_tokens.append(fired_tokens)\n",
    "    all_reconstructions.append(reconstruction)\n",
    "    \n",
    "    examples_found += len(fired_tokens)\n",
    "    # print(f\"Examples found: {examples_found}\")\n",
    "    # update description\n",
    "    pbar.set_description(f\"Examples found: {examples_found}\")\n",
    "    del cache\n",
    "    \n",
    "# flatten the list of lists\n",
    "all_token_dfs = pd.concat(all_token_dfs).reset_index(drop=True)\n",
    "all_fired_tokens = list_flatten(all_fired_tokens)\n",
    "all_reconstructions = torch.cat(all_reconstructions)\n",
    "all_feature_acts = torch.cat(all_feature_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a filtering here on feature list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts_df = pd.DataFrame(all_feature_acts.detach().cpu().numpy(), columns = [f\"feature_{i}\" for i in feature_list])\n",
    "feature_acts_df.shape\n",
    "feature_idx = 1\n",
    "# get non-zero activations\n",
    "\n",
    "all_positive_acts = all_feature_acts[all_feature_acts[:, feature_idx] > 0][:, feature_idx].detach()\n",
    "prop_positive_activations = 100*len(all_positive_acts) / (total_batches*batch_size_tokens)\n",
    "\n",
    "px.histogram(\n",
    "    all_positive_acts.cpu(),\n",
    "    nbins=50,\n",
    "    title=f\"Histogram of positive activations of F{feature_list[feature_idx]} - {prop_positive_activations:.3f}% of activations were positive\",\n",
    "    labels={\"value\": \"Activation\"},\n",
    "    width=800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_activations = feature_acts_df.sort_values(f\"feature_{feature_list[feature_idx]}\", ascending=False).head(10)\n",
    "all_token_dfs.iloc[top_10_activations.index].join(feature_acts_df[f\"feature_{feature_list[feature_idx]}\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the decoder weights {sae.W_dec.shape})\")\n",
    "print(f\"Shape of the model unembed {model.W_U.shape}\")\n",
    "projection_matrix = sae.W_dec @ model.W_U\n",
    "print(f\"Shape of the projection matrix {projection_matrix.shape}\")\n",
    "\n",
    "# then we take the top_k tokens per feature and decode them\n",
    "top_k = 10\n",
    "# let's do this for 100 random features\n",
    "_, top_k_tokens = torch.topk(projection_matrix[feature_list], top_k, dim=1)\n",
    "\n",
    "\n",
    "feature_df = pd.DataFrame(top_k_tokens.cpu().numpy(), index = [f\"feature_{i}\" for i in feature_list]).T\n",
    "feature_df.index = [f\"token_{i}\" for i in range(top_k)]\n",
    "top_logits_df = feature_df.map(lambda x: model.tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_logits_df[f\"feature_{feature_list[feature_idx]}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "\n",
    "all_tokens = torch.cat([activation_store.get_batch_tokens() for _ in range(64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_step = \"500M\"\n",
    "\n",
    "features = torch.randint(0, model.cfg.d_model*8, (512,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in tqdm(range(12)):\n",
    "    FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{l}\", ckpt_step)\n",
    "    BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{l}\", ckpt_step)\n",
    "    BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{l}\")\n",
    "\n",
    "    print(f\"Loading SAEs for layer {l} at {ckpt_step}\")\n",
    "\n",
    "    sae_vis_config = SaeVisConfig(\n",
    "        hook_point = f\"blocks.{l}.hook_resid_post\",\n",
    "        features = features,\n",
    "        verbose = False,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "        fwd_vis_data = SaeVisData.create(\n",
    "            encoder = fwd_sae,\n",
    "            model = model,\n",
    "            tokens = all_tokens,\n",
    "            cfg = sae_vis_config,\n",
    "        )\n",
    "        fwd_vis_data.save_json(f\"vis/l{l}_fwd.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load forward SAE for layer {l} - {e}\")\n",
    "\n",
    "    try:\n",
    "        bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "        bwd_vis_data = SaeVisData.create(\n",
    "            encoder = bwd_sae,\n",
    "            model = model,\n",
    "            tokens = all_tokens,\n",
    "            cfg = sae_vis_config,\n",
    "        )\n",
    "        bwd_vis_data.save_json(f\"vis/l{l}_bwd.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load backward SAE for layer {l} - {e}\")\n",
    "\n",
    "    try:\n",
    "        base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)\n",
    "        base_vis_data = SaeVisData.create(\n",
    "            encoder = base_sae,\n",
    "            model = model,\n",
    "            tokens = all_tokens,\n",
    "            cfg = sae_vis_config,\n",
    "        )\n",
    "        base_vis_data.save_json(f\"vis/l{l}_base.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base SAE for layer {l} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_shared_items(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    shared_items = set1.intersection(set2)\n",
    "    return len(shared_items)\n",
    "\n",
    "for l in tqdm(range(1, 11)):\n",
    "    fwd_data = json.load(open(f\"vis/l{l+1}_fwd.json\", 'r'))['feature_data_dict']\n",
    "    bwd_data = json.load(open(f\"vis/l{l-1}_bwd.json\", 'r'))['feature_data_dict']\n",
    "    base_data = json.load(open(f\"vis/l{l}_base.json\", 'r'))['feature_data_dict']\n",
    "\n",
    "    fwd_scores = {\n",
    "        'feature': [],\n",
    "        'top_logits': [],\n",
    "        'bottom_logits': [],\n",
    "        'max_toks': [],\n",
    "    }\n",
    "\n",
    "    bwd_scores = {\n",
    "        'feature': [],\n",
    "        'top_logits': [],\n",
    "        'bottom_logits': [],\n",
    "        'max_toks': [],\n",
    "    }\n",
    "\n",
    "    base_scores = {\n",
    "        'feature': [],\n",
    "        'top_logits': [],\n",
    "        'bottom_logits': [],\n",
    "        'max_toks': [],\n",
    "    }\n",
    "\n",
    "    for data, scores in tqdm(zip([fwd_data, bwd_data, base_data], [fwd_scores, bwd_scores, base_scores])):\n",
    "        for f, f_data in data.items():\n",
    "            logit_data = f_data['logits_table_data']\n",
    "            top_logits = logit_data['top_token_ids']\n",
    "            bottom_logits = logit_data['bottom_token_ids']\n",
    "\n",
    "            token_data = f_data['sequence_data']['seq_group_data'][0]['seq_data']\n",
    "            max_toks = []\n",
    "\n",
    "            for seq in token_data[:10]:\n",
    "                tok_ids, f_acts, loss_contrib = seq['token_ids'], seq['feat_acts'], seq['loss_contribution']\n",
    "                assert len(tok_ids) == len(f_acts) == len(loss_contrib)\n",
    "                max_tok = tok_ids[np.argmax(np.array(f_acts) + np.array(loss_contrib))]\n",
    "                max_toks.append(max_tok)\n",
    "\n",
    "            scores['feature'].append(f)\n",
    "            scores['top_logits'].append(top_logits)\n",
    "            scores['bottom_logits'].append(bottom_logits)\n",
    "            scores['max_toks'].append(max_toks)\n",
    "\n",
    "    fwd_df = pd.DataFrame(fwd_scores)\n",
    "    bwd_df = pd.DataFrame(bwd_scores)\n",
    "    base_df = pd.DataFrame(base_scores)\n",
    "\n",
    "    fwd_df = fwd_df.add_suffix('_fwd')\n",
    "    bwd_df = bwd_df.add_suffix('_bwd')\n",
    "    base_df = base_df.add_suffix('_base')\n",
    "\n",
    "    total_df = pd.concat([fwd_df, bwd_df, base_df], axis=1)\n",
    "\n",
    "    total_df['shared_fwd_top_logits'] = total_df.apply(lambda x: count_shared_items(x['top_logits_fwd'], x['top_logits_base']), axis=1)\n",
    "    total_df['shared_fwd_bottom_logits'] = total_df.apply(lambda x: count_shared_items(x['bottom_logits_fwd'], x['bottom_logits_base']), axis=1)\n",
    "    total_df['shared_fwd_max_toks'] = total_df.apply(lambda x: count_shared_items(x['max_toks_fwd'], x['max_toks_base']), axis=1)\n",
    "\n",
    "    total_df['shared_bwd_top_logits'] = total_df.apply(lambda x: count_shared_items(x['top_logits_bwd'], x['top_logits_base']), axis=1)\n",
    "    total_df['shared_bwd_bottom_logits'] = total_df.apply(lambda x: count_shared_items(x['bottom_logits_bwd'], x['bottom_logits_base']), axis=1)\n",
    "    total_df['shared_bwd_max_toks'] = total_df.apply(lambda x: count_shared_items(x['max_toks_bwd'], x['max_toks_base']), axis=1)\n",
    "\n",
    "    result_df = total_df[['feature_base', 'shared_fwd_top_logits', 'shared_fwd_bottom_logits', 'shared_fwd_max_toks', 'shared_bwd_top_logits', 'shared_bwd_bottom_logits', 'shared_bwd_max_toks']]\n",
    "    result_df.to_csv(f\"vis/l{l}_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "palette = sns.color_palette('flare', as_cmap=False, n_colors=10)\n",
    "palette_duo = [palette[0], palette[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "\n",
    "all_results_df = []\n",
    "\n",
    "for l in range(1, 11):\n",
    "    result_df = pd.read_csv(f\"vis/l{l}_result.csv\")\n",
    "    #result_df.iloc[:, 1:] = result_df.iloc[:, 1:].map(lambda x: 1 if x >= threshold else 0)\n",
    "    result_df['layer'] = l\n",
    "    \n",
    "    all_results_df.append(result_df)\n",
    "\n",
    "all_results_df = pd.concat(all_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df['Backward'] = (all_results_df['shared_bwd_top_logits'] + all_results_df['shared_bwd_bottom_logits'] + all_results_df['shared_bwd_max_toks']) / .3\n",
    "all_results_df['Forward'] = (all_results_df['shared_fwd_top_logits'] + all_results_df['shared_fwd_bottom_logits'] + all_results_df['shared_fwd_max_toks']) / .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = all_results_df[['layer', 'Forward', 'Backward']].melt(id_vars='layer', var_name='Transfer', value_name='Transferability')\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=120)\n",
    "sns.set_theme()\n",
    "ax = sns.barplot(\n",
    "    data=plot_df.groupby(['layer', 'Transfer']).mean(),\n",
    "    x='layer',\n",
    "    y='Transferability',\n",
    "    hue='Transfer',\n",
    "    hue_order=['Forward', 'Backward'],\n",
    "    palette=palette_duo,\n",
    ")\n",
    "\n",
    "ax.title.set_fontsize(13)\n",
    "ax.xaxis.label.set_fontsize(10)\n",
    "ax.yaxis.label.set_fontsize(10)\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax.xaxis.labelpad = 10\n",
    "ax.yaxis.labelpad = 10\n",
    "\n",
    "# Set title and move legend out of the plot\n",
    "plt.title(\"Feature Transfer\")\n",
    "plt.xlabel(\"Layer\")\n",
    "# make y axis label in %\n",
    "plt.ylabel(\"Shared tokens (%)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "sns.move_legend(ax, \"lower center\", bbox_to_anchor=(.5, -0.32), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/f_transfer.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Literal, NamedTuple, Callable\n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "\n",
    "class SaeReconstructionCache(NamedTuple):\n",
    "    sae_in: torch.Tensor\n",
    "    feature_acts: torch.Tensor\n",
    "    sae_out: torch.Tensor\n",
    "    sae_error: torch.Tensor\n",
    "\n",
    "\n",
    "def track_grad(tensor: torch.Tensor) -> None:\n",
    "    \"\"\"wrapper around requires_grad and retain_grad\"\"\"\n",
    "    tensor.requires_grad_(True)\n",
    "    tensor.retain_grad()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ApplySaesAndRunOutput:\n",
    "    model_output: torch.Tensor\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    sae_activations: dict[str, SaeReconstructionCache]\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        \"\"\"Helper to zero grad all tensors in this object.\"\"\"\n",
    "        self.model_output.grad = None\n",
    "        for act in self.model_activations.values():\n",
    "            act.grad = None\n",
    "        for cache in self.sae_activations.values():\n",
    "            cache.sae_in.grad = None\n",
    "            cache.feature_acts.grad = None\n",
    "            cache.sae_out.grad = None\n",
    "            cache.sae_error.grad = None\n",
    "\n",
    "\n",
    "def apply_saes_and_run(\n",
    "    model: HookedTransformer,\n",
    "    saes: dict[str, SAE],\n",
    "    input: Any,\n",
    "    include_error_term: bool = True,\n",
    "    track_model_hooks: list[str] | None = None,\n",
    "    return_type: Literal[\"logits\", \"loss\"] = \"logits\",\n",
    "    track_grads: bool = False,\n",
    ") -> ApplySaesAndRunOutput:\n",
    "    \"\"\"\n",
    "    Apply the SAEs to the model at the specific hook points, and run the model.\n",
    "    By default, this will include a SAE error term which guarantees that the SAE\n",
    "    will not affect model output. This function is designed to work correctly with\n",
    "    backprop as well, so it can be used for gradient-based feature attribution.\n",
    "\n",
    "    Args:\n",
    "        model: the model to run\n",
    "        saes: the SAEs to apply\n",
    "        input: the input to the model\n",
    "        include_error_term: whether to include the SAE error term to ensure the SAE doesn't affect model output. Default True\n",
    "        track_model_hooks: a list of hook points to record the activations and gradients. Default None\n",
    "        return_type: this is passed to the model.run_with_hooks function. Default \"logits\"\n",
    "        track_grads: whether to track gradients. Default False\n",
    "    \"\"\"\n",
    "\n",
    "    fwd_hooks = []\n",
    "    bwd_hooks = []\n",
    "\n",
    "    sae_activations: dict[str, SaeReconstructionCache] = {}\n",
    "    model_activations: dict[str, torch.Tensor] = {}\n",
    "\n",
    "    # this hook just track the SAE input, output, features, and error. If `track_grads=True`, it also ensures\n",
    "    # that requires_grad is set to True and retain_grad is called for intermediate values.\n",
    "    def reconstruction_hook(sae_in: torch.Tensor, hook: HookPoint, hook_point: str):  # noqa: ARG001\n",
    "        sae = saes[hook_point]\n",
    "        feature_acts = sae.encode(sae_in)\n",
    "        sae_out = sae.decode(feature_acts)\n",
    "        sae_error = (sae_in - sae_out).detach().clone()\n",
    "        if track_grads:\n",
    "            track_grad(sae_error)\n",
    "            track_grad(sae_out)\n",
    "            track_grad(feature_acts)\n",
    "            track_grad(sae_in)\n",
    "        sae_activations[hook_point] = SaeReconstructionCache(\n",
    "            sae_in=sae_in,\n",
    "            feature_acts=feature_acts,\n",
    "            sae_out=sae_out,\n",
    "            sae_error=sae_error,\n",
    "        )\n",
    "\n",
    "        if include_error_term:\n",
    "            return sae_out + sae_error\n",
    "        return sae_out\n",
    "\n",
    "    def sae_bwd_hook(output_grads: torch.Tensor, hook: HookPoint):  # noqa: ARG001\n",
    "        # this just passes the output grads to the input, so the SAE gets the same grads despite the error term hackery\n",
    "        return (output_grads,)\n",
    "\n",
    "    # this hook just records model activations, and ensures that intermediate activations have gradient tracking turned on if needed\n",
    "    def tracking_hook(hook_input: torch.Tensor, hook: HookPoint, hook_point: str):  # noqa: ARG001\n",
    "        model_activations[hook_point] = hook_input\n",
    "        if track_grads:\n",
    "            track_grad(hook_input)\n",
    "        return hook_input\n",
    "\n",
    "    for hook_point in saes.keys():\n",
    "        fwd_hooks.append(\n",
    "            (hook_point, partial(reconstruction_hook, hook_point=hook_point))\n",
    "        )\n",
    "        bwd_hooks.append((hook_point, sae_bwd_hook))\n",
    "    for hook_point in track_model_hooks or []:\n",
    "        fwd_hooks.append((hook_point, partial(tracking_hook, hook_point=hook_point)))\n",
    "\n",
    "    # now, just run the model while applying the hooks\n",
    "    with model.hooks(fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks):\n",
    "        model_output = model(input, return_type=return_type)\n",
    "\n",
    "    return ApplySaesAndRunOutput(\n",
    "        model_output=model_output,\n",
    "        model_activations=model_activations,\n",
    "        sae_activations=sae_activations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Literal, NamedTuple\n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import HookedSAETransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "@dataclass\n",
    "class AttributionGrads:\n",
    "    metric: torch.Tensor\n",
    "    model_output: torch.Tensor\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    sae_activations: dict[str, SaeReconstructionCache]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Attribution:\n",
    "    model_attributions: dict[str, torch.Tensor]\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    model_grads: dict[str, torch.Tensor]\n",
    "    sae_feature_attributions: dict[str, torch.Tensor]\n",
    "    sae_feature_activations: dict[str, torch.Tensor]\n",
    "    sae_feature_grads: dict[str, torch.Tensor]\n",
    "    sae_errors_attribution_proportion: dict[str, float]\n",
    "\n",
    "\n",
    "def calculate_attribution_grads(\n",
    "    model: HookedSAETransformer,\n",
    "    prompt: str,\n",
    "    metric_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    track_hook_points: list[str] | None = None,\n",
    "    include_saes: dict[str, SAE] | None = None,\n",
    "    return_logits: bool = True,\n",
    "    include_error_term: bool = True,\n",
    ") -> AttributionGrads:\n",
    "    \"\"\"\n",
    "    Wrapper around apply_saes_and_run that calculates gradients wrt to the metric_fn.\n",
    "    Tracks grads for both SAE feature and model neurons, and returns them in a structured format.\n",
    "    \"\"\"\n",
    "    output = apply_saes_and_run(\n",
    "        model,\n",
    "        saes=include_saes or {},\n",
    "        input=prompt,\n",
    "        return_type=\"logits\" if return_logits else \"loss\",\n",
    "        track_model_hooks=track_hook_points,\n",
    "        include_error_term=include_error_term,\n",
    "        track_grads=True,\n",
    "    )\n",
    "    metric = metric_fn(output.model_output)\n",
    "    output.zero_grad()\n",
    "    metric.backward()\n",
    "    return AttributionGrads(\n",
    "        metric=metric,\n",
    "        model_output=output.model_output,\n",
    "        model_activations=output.model_activations,\n",
    "        sae_activations=output.sae_activations,\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_feature_attribution(\n",
    "    model: HookedSAETransformer,\n",
    "    input: Any,\n",
    "    metric_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    track_hook_points: list[str] | None = None,\n",
    "    include_saes: dict[str, SAE] | None = None,\n",
    "    return_logits: bool = True,\n",
    "    include_error_term: bool = True,\n",
    ") -> Attribution:\n",
    "    \"\"\"\n",
    "    Calculate feature attribution for SAE features and model neurons following\n",
    "    the procedure in https://transformer-circuits.pub/2024/march-update/index.html#feature-heads.\n",
    "    This include the SAE error term by default, so inserting the SAE into the calculation is\n",
    "    guaranteed to not affect the model output. This can be disabled by setting `include_error_term=False`.\n",
    "\n",
    "    Args:\n",
    "        model: The model to calculate feature attribution for.\n",
    "        input: The input to the model.\n",
    "        metric_fn: A function that takes the model output and returns a scalar metric.\n",
    "        track_hook_points: A list of model hook points to track activations for, if desired\n",
    "        include_saes: A dictionary of SAEs to include in the calculation. The key is the hook point to apply the SAE to.\n",
    "        return_logits: Whether to return the model logits or loss. This is passed to TLens, so should match whatever the metric_fn expects (probably logits)\n",
    "        include_error_term: Whether to include the SAE error term in the calculation. This is recommended, as it ensures that the SAE will not affecting the model output.\n",
    "    \"\"\"\n",
    "    # first, calculate gradients wrt to the metric_fn.\n",
    "    # these will be multiplied with the activation values to get the attributions\n",
    "    outputs_with_grads = calculate_attribution_grads(\n",
    "        model,\n",
    "        input,\n",
    "        metric_fn,\n",
    "        track_hook_points,\n",
    "        include_saes=include_saes,\n",
    "        return_logits=return_logits,\n",
    "        include_error_term=include_error_term,\n",
    "    )\n",
    "    model_attributions = {}\n",
    "    model_activations = {}\n",
    "    model_grads = {}\n",
    "    sae_feature_attributions = {}\n",
    "    sae_feature_activations = {}\n",
    "    sae_feature_grads = {}\n",
    "    sae_error_proportions = {}\n",
    "    # this code is long, but all it's doing is multiplying the grads by the activations\n",
    "    # and recording grads, acts, and attributions in dictionaries to return to the user\n",
    "    with torch.no_grad():\n",
    "        for name, act in outputs_with_grads.model_activations.items():\n",
    "            assert act.grad is not None\n",
    "            raw_activation = act.detach().clone()\n",
    "            model_attributions[name] = (act.grad * raw_activation).detach().clone()\n",
    "            model_activations[name] = raw_activation\n",
    "            model_grads[name] = act.grad.detach().clone()\n",
    "        for name, act in outputs_with_grads.sae_activations.items():\n",
    "            assert act.feature_acts.grad is not None\n",
    "            assert act.sae_out.grad is not None\n",
    "            raw_activation = act.feature_acts.detach().clone()\n",
    "            sae_feature_attributions[name] = (\n",
    "                (act.feature_acts.grad * raw_activation).detach().clone()\n",
    "            )\n",
    "            sae_feature_activations[name] = raw_activation\n",
    "            sae_feature_grads[name] = act.feature_acts.grad.detach().clone()\n",
    "            if include_error_term:\n",
    "                assert act.sae_error.grad is not None\n",
    "                error_grad_norm = act.sae_error.grad.norm().item()\n",
    "            else:\n",
    "                error_grad_norm = 0\n",
    "            sae_out_norm = act.sae_out.grad.norm().item()\n",
    "            sae_error_proportions[name] = error_grad_norm / (\n",
    "                sae_out_norm + error_grad_norm + EPS\n",
    "            )\n",
    "        return Attribution(\n",
    "            model_attributions=model_attributions,\n",
    "            model_activations=model_activations,\n",
    "            model_grads=model_grads,\n",
    "            sae_feature_attributions=sae_feature_attributions,\n",
    "            sae_feature_activations=sae_feature_activations,\n",
    "            sae_feature_grads=sae_feature_grads,\n",
    "            sae_errors_attribution_proportion=sae_error_proportions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df = pd.read_csv(\"eval/test_attr.csv\")\n",
    "\n",
    "def check_single_token(x):\n",
    "    try:\n",
    "        model.to_single_token(\" \" + x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "attr_df['Correct Single Token'] = attr_df['Correct Answer'].apply(check_single_token)\n",
    "attr_df['Wrong Single Token'] = attr_df['Wrong Answer'].apply(check_single_token)\n",
    "\n",
    "attr_df = attr_df[(attr_df['Correct Single Token']) & (attr_df['Wrong Single Token'])].iloc[:, :-2].drop_duplicates()\n",
    "attr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(idx):\n",
    "    row = attr_df.iloc[idx]\n",
    "    prompt = row['Sentence']\n",
    "    \n",
    "    pos_token = model.tokenizer.encode(\" \" + row['Correct Answer'], add_special_tokens=False)\n",
    "    neg_token = model.tokenizer.encode(\" \" + row['Wrong Answer'], add_special_tokens=False)\n",
    "\n",
    "    return prompt, pos_token, neg_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_feature_to_long_df(sparse_tensor: torch.Tensor) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a sparse tensor to a long format pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(sparse_tensor.detach().cpu().numpy())\n",
    "    df_long = df.melt(ignore_index=False, var_name='column', value_name='value')\n",
    "    df_long.columns = [\"feature\", \"attribution\"]\n",
    "    df_long_nonzero = df_long[df_long['attribution'] != 0]\n",
    "    df_long_nonzero = df_long_nonzero.reset_index().rename(columns={'index': 'position'})\n",
    "    return df_long_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_step = \"100M\"\n",
    "\n",
    "base_fa_scores = []\n",
    "fwd_fa_scores = []\n",
    "bwd_fa_scores = []\n",
    "\n",
    "for l in tqdm(range(1,11)):\n",
    "    \n",
    "    FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{l}\", ckpt_step)\n",
    "    BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{l}\", ckpt_step)\n",
    "    BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{l}\")\n",
    "\n",
    "    fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "    bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "    base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)\n",
    "    \n",
    "    for i in range(attr_df.shape[0]):\n",
    "        prompt, pos_token, neg_token = get_prompt(i)\n",
    "        \n",
    "        def metric_fn(logits: torch.tensor, pos_token: torch.tensor =pos_token, neg_token: torch.Tensor=neg_token) -> torch.Tensor:\n",
    "            return logits[0,-1,pos_token] - logits[0,-1,neg_token]\n",
    "\n",
    "        base_fa = calculate_feature_attribution(\n",
    "            input = prompt,\n",
    "            model = model,\n",
    "            metric_fn = metric_fn,\n",
    "            include_saes={base_sae.cfg.hook_name: base_sae},\n",
    "            include_error_term=True,\n",
    "            return_logits=True,\n",
    "        )\n",
    "\n",
    "        #fwd_fa = calculate_feature_attribution(\n",
    "        #    input = prompt,\n",
    "        #    model = model,\n",
    "        #    metric_fn = metric_fn,\n",
    "        #    include_saes={fwd_sae.cfg.hook_name: fwd_sae},\n",
    "        #    include_error_term=True,\n",
    "        #    return_logits=True,\n",
    "        #)\n",
    "\n",
    "        #bwd_fa = calculate_feature_attribution(\n",
    "        #    input = prompt,\n",
    "        #    model = model,\n",
    "        #    metric_fn = metric_fn,\n",
    "        #    include_saes={bwd_sae.cfg.hook_name: bwd_sae},\n",
    "        #    include_error_term=True,\n",
    "        #    return_logits=True,\n",
    "        #)\n",
    "\n",
    "        base_fa_df = convert_sparse_feature_to_long_df(base_fa.sae_feature_attributions[base_sae.cfg.hook_name][0])\n",
    "        #fwd_fa_df = convert_sparse_feature_to_long_df(fwd_fa.sae_feature_attributions[fwd_sae.cfg.hook_name][0])\n",
    "        #bwd_fa_df = convert_sparse_feature_to_long_df(bwd_fa.sae_feature_attributions[bwd_sae.cfg.hook_name][0])\n",
    "\n",
    "        base_fa_scores.append(base_fa_df['attribution'].max())\n",
    "        #fwd_fa_scores.append(fwd_fa_df['attribution'].max())\n",
    "        #bwd_fa_scores.append(bwd_fa_df['attribution'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer\": np.arange(1,11)[:, None].repeat(len(attr_df)),\n",
    "        \"No transfer\": base_fa_scores,\n",
    "        #\"Forward\": fwd_fa_scores,\n",
    "        #\"Backward\": bwd_fa_scores,\n",
    "    }\n",
    ")\n",
    "\n",
    "scores_df = scores_df.melt(id_vars='Layer', var_name='Transfer', value_name='Max Attribution Score')\n",
    "#scores_df.to_csv(f\"eval/dla_scores_base.csv\", index=False)\n",
    "avg_scores_df = scores_df.groupby(['Layer', 'Transfer']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dla_scores_base = pd.read_csv(\"eval/dla_scores_base.csv\")\n",
    "dla_scores_100 = pd.read_csv(\"eval/dla_scores_100M.csv\")\n",
    "dla_scores_200 = pd.read_csv(\"eval/dla_scores_200M.csv\")\n",
    "dla_scores_300 = pd.read_csv(\"eval/dla_scores_300M.csv\")\n",
    "dla_scores_400 = pd.read_csv(\"eval/dla_scores_400M.csv\")\n",
    "dla_scores_500 = pd.read_csv(\"eval/dla_scores_500M.csv\")\n",
    "\n",
    "dla_scores_100['Checkpoint'] = '100M'\n",
    "dla_scores_200['Checkpoint'] = '200M'\n",
    "dla_scores_300['Checkpoint'] = '300M'\n",
    "dla_scores_400['Checkpoint'] = '400M'\n",
    "dla_scores_500['Checkpoint'] = '500M'\n",
    "\n",
    "dla_scores = pd.concat([dla_scores_100, dla_scores_200, dla_scores_300, dla_scores_400, dla_scores_500])\n",
    "dla_scores = dla_scores[dla_scores['Transfer'] != 'No transfer']\n",
    "avg_scores_df = dla_scores.groupby(['Transfer', 'Checkpoint']).mean().reset_index()\n",
    "avg_base_scores = dla_scores_base.groupby(['Transfer']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=120)\n",
    "sns.set_theme()\n",
    "ax0 = sns.lineplot(\n",
    "    avg_scores_df,\n",
    "    x=\"Checkpoint\",\n",
    "    y=\"Max Attribution Score\",\n",
    "    hue=\"Transfer\",\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    palette=palette_duo,\n",
    "    hue_order=['Forward', 'Backward']\n",
    ")\n",
    "\n",
    "plt.hlines(avg_base_scores['Max Attribution Score'], 0, 4, linestyles='dashed', label='No transfer', color='grey')\n",
    "\n",
    "\n",
    "ax0.title.set_fontsize(13)\n",
    "ax0.xaxis.label.set_fontsize(10)\n",
    "ax0.yaxis.label.set_fontsize(10)\n",
    "ax0.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax0.xaxis.labelpad = 10\n",
    "ax0.yaxis.labelpad = 10\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(\"Direct Logit Attribution Scores\")\n",
    "plt.ylabel(\"Avg. Attribution Score\")\n",
    "# add baseline to legend\n",
    "plt.legend()\n",
    "sns.move_legend(ax0, \"lower center\", bbox_to_anchor=(.5, -0.35), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/dla_scores.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_dla_scores = dla_scores[dla_scores['Transfer'] == 'Forward'].drop(columns=['Transfer'])\n",
    "bwd_dla_scores = dla_scores[dla_scores['Transfer'] == 'Backward'].drop(columns=['Transfer'])\n",
    "\n",
    "avg_fwd_scores = fwd_dla_scores.groupby(['Checkpoint', 'Layer']).mean().reset_index()\n",
    "avg_bwd_scores = bwd_dla_scores.groupby(['Checkpoint', 'Layer']).mean().reset_index()\n",
    "avg_base_scores = dla_scores_base.groupby(['Transfer', 'Layer']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10.5, 4.5), dpi=120)\n",
    "sns.set_theme()\n",
    "ax0 = sns.lineplot(\n",
    "    avg_fwd_scores,\n",
    "    x=\"Checkpoint\",\n",
    "    y=\"Max Attribution Score\",\n",
    "    hue=\"Layer\",\n",
    "    ax=ax[0],\n",
    "    legend=False,\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "ax1 = sns.lineplot(\n",
    "    avg_bwd_scores,\n",
    "    x=\"Checkpoint\",\n",
    "    y=\"Max Attribution Score\",\n",
    "    hue=\"Layer\",\n",
    "    ax=ax[1],\n",
    "    legend='full',\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "ax[0].set_title(\"Forward Feature Attribution Scores\")\n",
    "ax[0].set_ylabel(\"Attribution Score\")\n",
    "ax[0].set_xlabel(\"Checkpoint\")\n",
    "\n",
    "ax[1].set_title(\"Backward Feature Attribution Scores\")\n",
    "ax[1].set_ylabel(\"Attribution Score\")\n",
    "ax[1].set_xlabel(\"Checkpoint\")\n",
    "\n",
    "for a in ax:\n",
    "    a.title.set_fontsize(13)\n",
    "    a.xaxis.label.set_fontsize(10)\n",
    "    a.yaxis.label.set_fontsize(10)\n",
    "    a.tick_params(axis='both', which='major', labelsize=10)\n",
    "    a.xaxis.labelpad = 10\n",
    "    a.yaxis.labelpad = 10\n",
    "\n",
    "# Adjust legend placement\n",
    "ax[1].legend(title=\"Layer\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Apply tight layout to adjust all elements\n",
    "plt.tight_layout()\n",
    "sns.move_legend(ax1, \"lower center\", bbox_to_anchor=(-0.13, -0.35), ncol=5, title=None, frameon=False)\n",
    "plt.savefig(\"img/dla_indv_scores.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_step = \"500M\"\n",
    "\n",
    "base_fwd_similarities = []\n",
    "base_bwd_similarities = []\n",
    "\n",
    "for i in tqdm(range(1, 11)):\n",
    "    BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{i}\", ckpt_step)\n",
    "    base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)\n",
    "\n",
    "    base_W_dec = base_sae.W_dec\n",
    "\n",
    "    FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{i}\", ckpt_step)\n",
    "    BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{i}\", ckpt_step)\n",
    "    \n",
    "    fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "    bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "    \n",
    "    fwd_W_dec = fwd_sae.W_dec\n",
    "    bwd_W_dec = bwd_sae.W_dec\n",
    "\n",
    "    base_fwd_sim = (fwd_W_dec @ base_W_dec.T).max(-1).values.mean()\n",
    "    base_bwd_sim = (bwd_W_dec @ base_W_dec.T).max(-1).values.mean()\n",
    "\n",
    "    base_fwd_similarities.append(base_fwd_sim.item())\n",
    "    base_bwd_similarities.append(base_bwd_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=120)\n",
    "sns.set_theme()\n",
    "ax0 = sns.lineplot(\n",
    "    x=np.arange(1, 11),\n",
    "    y=base_fwd_similarities,\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    color=palette[0],\n",
    ")\n",
    "\n",
    "ax1 = sns.lineplot(\n",
    "    x=np.arange(1, 11),\n",
    "    y=base_bwd_similarities,\n",
    "    legend=False,\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    color=palette[-1],\n",
    ")\n",
    "\n",
    "ax0.title.set_fontsize(13)\n",
    "ax0.xaxis.label.set_fontsize(10)\n",
    "ax0.yaxis.label.set_fontsize(10)\n",
    "ax0.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax0.xaxis.labelpad = 10\n",
    "ax0.yaxis.labelpad = 10\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(\"MMCS between Transfer and No transfer SAEs\")\n",
    "plt.ylabel(\"MMCS\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.legend(title=\"Transfer\", labels=[\"Forward\", \"_\", \"Backward\", \"_\"], bbox_to_anchor=(1.03, 1), loc='upper left')\n",
    "plt.ylim(0.59, 0.91)\n",
    "sns.move_legend(ax0, \"lower center\", bbox_to_anchor=(.5, -0.35), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/mmcs_scores.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df = pd.read_csv(\"eval/human_interp.csv\").fillna(\"y\").drop(\"Feature\", axis=1)\n",
    "hi_df = hi_df.melt(id_vars='Layer', var_name='Transfer', value_name='Human Interpretability Score')\n",
    "hi_df['Human Interpretability Score'] = hi_df['Human Interpretability Score'].apply(lambda x: 0 if x == \"n\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_mask = (hi_df['Layer'] == 0) & (hi_df['Transfer'] == 'Forward')\n",
    "bwd_mask = (hi_df['Layer'] == 11) & (hi_df['Transfer'] == 'Backward')\n",
    "\n",
    "hi_df.loc[fwd_mask, 'Human Interpretability Score'] = 0\n",
    "hi_df.loc[bwd_mask, 'Human Interpretability Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5, 4.5), dpi=120)\n",
    "sns.set_theme()\n",
    "ax = sns.barplot(\n",
    "    hi_df,\n",
    "    x=\"Layer\",\n",
    "    y=\"Human Interpretability Score\",\n",
    "    hue=\"Transfer\",\n",
    "    orient=\"v\",\n",
    "    hue_order=[\"Forward\", \"Backward\", \"No transfer\"],\n",
    "    palette=palette_duo + ['darkgrey'],\n",
    ")\n",
    "\n",
    "ax.title.set_fontsize(13)\n",
    "ax.xaxis.label.set_fontsize(10)\n",
    "ax.yaxis.label.set_fontsize(10)\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax.xaxis.labelpad = 10\n",
    "ax.yaxis.labelpad = 10\n",
    "\n",
    "# Set title and move legend out of the plot\n",
    "plt.title(\"Human Interpretability Scores\")\n",
    "plt.legend()\n",
    "sns.move_legend(ax, \"lower center\", bbox_to_anchor=(.5, -0.32), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/hi_scores.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
