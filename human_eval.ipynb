{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, ActivationsStore, LanguageModelSAERunnerConfig\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "palette = sns.color_palette('flare', as_cmap=False, n_colors=10)\n",
    "palette_duo = [palette[0], palette[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"pythia-160m-deduped\",\n",
    "    hook_name=None,\n",
    "    hook_layer=None,\n",
    "    dataset_path=\"NeelNanda/pile-small-tokenized-2b\",\n",
    "    is_dataset_tokenized=True,\n",
    "    context_size=1024,\n",
    "    streaming=True,\n",
    "    # SAE Parameters\n",
    "    architecture=\"jumprelu\",\n",
    "    d_in=768,\n",
    "    d_sae=None,\n",
    "    b_dec_init_method=\"zeros\",\n",
    "    expansion_factor=8,\n",
    "    activation_fn=\"relu\",  # relu, tanh-relu, topk\n",
    "    normalize_sae_decoder=True,\n",
    "    from_pretrained_path=None,\n",
    "    apply_b_dec_to_input=False,\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=128,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    dtype=\"float32\",\n",
    "    prepend_bos=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-160m-deduped\", device = device)\n",
    "\n",
    "direction = \"backward\"\n",
    "ckpt_step = \"500M\"\n",
    "sae_idx = 8\n",
    "transfer = True\n",
    "\n",
    "SAE_PATH = \"/workspace/huggingface/hub/models--mech-interp--pythia-160m-deduped-rs-post/snapshots/49befceb8d1f7be1d4b3c6bef477c4e899def430\"\n",
    "\n",
    "#FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{sae_idx}\", ckpt_step)\n",
    "#BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{sae_idx}\", ckpt_step)\n",
    "#BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{sae_idx}\")\n",
    "\n",
    "#fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "#bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "#base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_store = ActivationsStore.from_config(model, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_flatten(nested_list):\n",
    "    return [x for y in nested_list for x in y]\n",
    "\n",
    "# A very handy function Neel wrote to get context around a feature activation\n",
    "def make_token_df(tokens, len_prefix=5, len_suffix=3, model = model):\n",
    "    str_tokens = [model.to_str_tokens(t) for t in tokens]\n",
    "    unique_token = [[f\"{s}/{i}\" for i, s in enumerate(str_tok)] for str_tok in str_tokens]\n",
    "    \n",
    "    context = []\n",
    "    prompt = []\n",
    "    pos = []\n",
    "    label = []\n",
    "    for b in range(tokens.shape[0]):\n",
    "        for p in range(tokens.shape[1]):\n",
    "            prefix = \"\".join(str_tokens[b][max(0, p-len_prefix):p])\n",
    "            if p==tokens.shape[1]-1:\n",
    "                suffix = \"\"\n",
    "            else:\n",
    "                suffix = \"\".join(str_tokens[b][p+1:min(tokens.shape[1]-1, p+1+len_suffix)])\n",
    "            current = str_tokens[b][p]\n",
    "            context.append(f\"{prefix}|{current}|{suffix}\")\n",
    "            prompt.append(b)\n",
    "            pos.append(p)\n",
    "            label.append(f\"{b}/{p}\")\n",
    "    # print(len(batch), len(pos), len(context), len(label))\n",
    "    return pd.DataFrame(dict(\n",
    "        str_tokens=list_flatten(str_tokens),\n",
    "        unique_token=list_flatten(unique_token),\n",
    "        context=context,\n",
    "        prompt=prompt,\n",
    "        pos=pos,\n",
    "        label=label,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding max activating examples is a bit harder. To do this we need to calculate feature activations for a large number of tokens\n",
    "feature_list = torch.randint(0, sae.cfg.d_sae, (32,))\n",
    "examples_found = 0\n",
    "all_fired_tokens = []\n",
    "all_feature_acts = []\n",
    "all_reconstructions = []\n",
    "all_token_dfs = []\n",
    "\n",
    "total_batches = 32\n",
    "batch_size_prompts = activation_store.store_batch_size_prompts\n",
    "batch_size_tokens = activation_store.context_size * batch_size_prompts\n",
    "pbar = tqdm(range(total_batches))\n",
    "for i in pbar:\n",
    "    tokens = activation_store.get_batch_tokens()\n",
    "    tokens_df = make_token_df(tokens)\n",
    "    tokens_df[\"batch\"] = i\n",
    "    \n",
    "    flat_tokens = tokens.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = model.run_with_cache(tokens, stop_at_layer = sae.cfg.hook_layer + 1, names_filter = [sae.cfg.hook_name])\n",
    "        sae_in = cache[sae.cfg.hook_name]\n",
    "        feature_acts = sae.encode(sae_in).squeeze()\n",
    "\n",
    "        feature_acts = feature_acts.flatten(0,1)\n",
    "        fired_mask = (feature_acts[:, feature_list]).sum(dim=-1) > 0\n",
    "        fired_tokens = model.to_str_tokens(flat_tokens[fired_mask])\n",
    "        reconstruction = feature_acts[fired_mask][:, feature_list] @ sae.W_dec[feature_list]\n",
    "\n",
    "    token_df = tokens_df.iloc[fired_mask.cpu().nonzero().flatten().numpy()]\n",
    "    all_token_dfs.append(token_df)\n",
    "    all_feature_acts.append(feature_acts[fired_mask][:, feature_list])\n",
    "    all_fired_tokens.append(fired_tokens)\n",
    "    all_reconstructions.append(reconstruction)\n",
    "    \n",
    "    examples_found += len(fired_tokens)\n",
    "    # print(f\"Examples found: {examples_found}\")\n",
    "    # update description\n",
    "    pbar.set_description(f\"Examples found: {examples_found}\")\n",
    "    del cache\n",
    "    \n",
    "# flatten the list of lists\n",
    "all_token_dfs = pd.concat(all_token_dfs).reset_index(drop=True)\n",
    "all_fired_tokens = list_flatten(all_fired_tokens)\n",
    "all_reconstructions = torch.cat(all_reconstructions)\n",
    "all_feature_acts = torch.cat(all_feature_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a filtering here on feature list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts_df = pd.DataFrame(all_feature_acts.detach().cpu().numpy(), columns = [f\"feature_{i}\" for i in feature_list])\n",
    "feature_acts_df.shape\n",
    "feature_idx = 1\n",
    "# get non-zero activations\n",
    "\n",
    "all_positive_acts = all_feature_acts[all_feature_acts[:, feature_idx] > 0][:, feature_idx].detach()\n",
    "prop_positive_activations = 100*len(all_positive_acts) / (total_batches*batch_size_tokens)\n",
    "\n",
    "px.histogram(\n",
    "    all_positive_acts.cpu(),\n",
    "    nbins=50,\n",
    "    title=f\"Histogram of positive activations of F{feature_list[feature_idx]} - {prop_positive_activations:.3f}% of activations were positive\",\n",
    "    labels={\"value\": \"Activation\"},\n",
    "    width=800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_activations = feature_acts_df.sort_values(f\"feature_{feature_list[feature_idx]}\", ascending=False).head(10)\n",
    "all_token_dfs.iloc[top_10_activations.index].join(feature_acts_df[f\"feature_{feature_list[feature_idx]}\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the decoder weights {sae.W_dec.shape})\")\n",
    "print(f\"Shape of the model unembed {model.W_U.shape}\")\n",
    "projection_matrix = sae.W_dec @ model.W_U\n",
    "print(f\"Shape of the projection matrix {projection_matrix.shape}\")\n",
    "\n",
    "# then we take the top_k tokens per feature and decode them\n",
    "top_k = 10\n",
    "# let's do this for 100 random features\n",
    "_, top_k_tokens = torch.topk(projection_matrix[feature_list], top_k, dim=1)\n",
    "\n",
    "\n",
    "feature_df = pd.DataFrame(top_k_tokens.cpu().numpy(), index = [f\"feature_{i}\" for i in feature_list]).T\n",
    "feature_df.index = [f\"token_{i}\" for i in range(top_k)]\n",
    "top_logits_df = feature_df.map(lambda x: model.tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_logits_df[f\"feature_{feature_list[feature_idx]}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "\n",
    "all_tokens = torch.cat([activation_store.get_batch_tokens() for _ in range(64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_step = \"500M\"\n",
    "\n",
    "features = torch.randint(0, model.cfg.d_model*8, (512,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in tqdm(range(12)):\n",
    "    FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{l}\", ckpt_step)\n",
    "    BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{l}\", ckpt_step)\n",
    "    BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{l}\")\n",
    "\n",
    "    print(f\"Loading SAEs for layer {l} at {ckpt_step}\")\n",
    "\n",
    "    sae_vis_config = SaeVisConfig(\n",
    "        hook_point = f\"blocks.{l}.hook_resid_post\",\n",
    "        features = features,\n",
    "        verbose = False,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "        fwd_vis_data = SaeVisData.create(\n",
    "            encoder = fwd_sae,\n",
    "            model = model,\n",
    "            tokens = all_tokens,\n",
    "            cfg = sae_vis_config,\n",
    "        )\n",
    "        fwd_vis_data.save_json(f\"vis/l{l}_fwd.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load forward SAE for layer {l} - {e}\")\n",
    "\n",
    "    try:\n",
    "        bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "        bwd_vis_data = SaeVisData.create(\n",
    "            encoder = bwd_sae,\n",
    "            model = model,\n",
    "            tokens = all_tokens,\n",
    "            cfg = sae_vis_config,\n",
    "        )\n",
    "        bwd_vis_data.save_json(f\"vis/l{l}_bwd.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load backward SAE for layer {l} - {e}\")\n",
    "\n",
    "    try:\n",
    "        base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)\n",
    "        base_vis_data = SaeVisData.create(\n",
    "            encoder = base_sae,\n",
    "            model = model,\n",
    "            tokens = all_tokens,\n",
    "            cfg = sae_vis_config,\n",
    "        )\n",
    "        base_vis_data.save_json(f\"vis/l{l}_base.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load base SAE for layer {l} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_shared_items(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    shared_items = set1.intersection(set2)\n",
    "    return len(shared_items)\n",
    "\n",
    "for l in tqdm(range(1, 11)):\n",
    "    fwd_data = json.load(open(f\"vis/l{l+1}_fwd.json\", 'r'))['feature_data_dict']\n",
    "    bwd_data = json.load(open(f\"vis/l{l-1}_bwd.json\", 'r'))['feature_data_dict']\n",
    "    base_data = json.load(open(f\"vis/l{l}_base.json\", 'r'))['feature_data_dict']\n",
    "\n",
    "    fwd_scores = {\n",
    "        'feature': [],\n",
    "        'top_logits': [],\n",
    "        'bottom_logits': [],\n",
    "        'max_toks': [],\n",
    "    }\n",
    "\n",
    "    bwd_scores = {\n",
    "        'feature': [],\n",
    "        'top_logits': [],\n",
    "        'bottom_logits': [],\n",
    "        'max_toks': [],\n",
    "    }\n",
    "\n",
    "    base_scores = {\n",
    "        'feature': [],\n",
    "        'top_logits': [],\n",
    "        'bottom_logits': [],\n",
    "        'max_toks': [],\n",
    "    }\n",
    "\n",
    "    for data, scores in tqdm(zip([fwd_data, bwd_data, base_data], [fwd_scores, bwd_scores, base_scores])):\n",
    "        for f, f_data in data.items():\n",
    "            logit_data = f_data['logits_table_data']\n",
    "            top_logits = logit_data['top_token_ids']\n",
    "            bottom_logits = logit_data['bottom_token_ids']\n",
    "\n",
    "            token_data = f_data['sequence_data']['seq_group_data'][0]['seq_data']\n",
    "            max_toks = []\n",
    "\n",
    "            for seq in token_data[:10]:\n",
    "                tok_ids, f_acts, loss_contrib = seq['token_ids'], seq['feat_acts'], seq['loss_contribution']\n",
    "                assert len(tok_ids) == len(f_acts) == len(loss_contrib)\n",
    "                max_tok = tok_ids[np.argmax(np.array(f_acts) + np.array(loss_contrib))]\n",
    "                max_toks.append(max_tok)\n",
    "\n",
    "            scores['feature'].append(f)\n",
    "            scores['top_logits'].append(top_logits)\n",
    "            scores['bottom_logits'].append(bottom_logits)\n",
    "            scores['max_toks'].append(max_toks)\n",
    "\n",
    "    fwd_df = pd.DataFrame(fwd_scores)\n",
    "    bwd_df = pd.DataFrame(bwd_scores)\n",
    "    base_df = pd.DataFrame(base_scores)\n",
    "\n",
    "    fwd_df = fwd_df.add_suffix('_fwd')\n",
    "    bwd_df = bwd_df.add_suffix('_bwd')\n",
    "    base_df = base_df.add_suffix('_base')\n",
    "\n",
    "    total_df = pd.concat([fwd_df, bwd_df, base_df], axis=1)\n",
    "\n",
    "    total_df['shared_fwd_top_logits'] = total_df.apply(lambda x: count_shared_items(x['top_logits_fwd'], x['top_logits_base']), axis=1)\n",
    "    total_df['shared_fwd_bottom_logits'] = total_df.apply(lambda x: count_shared_items(x['bottom_logits_fwd'], x['bottom_logits_base']), axis=1)\n",
    "    total_df['shared_fwd_max_toks'] = total_df.apply(lambda x: count_shared_items(x['max_toks_fwd'], x['max_toks_base']), axis=1)\n",
    "\n",
    "    total_df['shared_bwd_top_logits'] = total_df.apply(lambda x: count_shared_items(x['top_logits_bwd'], x['top_logits_base']), axis=1)\n",
    "    total_df['shared_bwd_bottom_logits'] = total_df.apply(lambda x: count_shared_items(x['bottom_logits_bwd'], x['bottom_logits_base']), axis=1)\n",
    "    total_df['shared_bwd_max_toks'] = total_df.apply(lambda x: count_shared_items(x['max_toks_bwd'], x['max_toks_base']), axis=1)\n",
    "\n",
    "    result_df = total_df[['feature_base', 'shared_fwd_top_logits', 'shared_fwd_bottom_logits', 'shared_fwd_max_toks', 'shared_bwd_top_logits', 'shared_bwd_bottom_logits', 'shared_bwd_max_toks']]\n",
    "    result_df.to_csv(f\"vis/l{l}_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "palette = sns.color_palette('flare', as_cmap=False, n_colors=10)\n",
    "palette_duo = [palette[0], palette[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "\n",
    "all_results_df = []\n",
    "\n",
    "for l in range(1, 11):\n",
    "    result_df = pd.read_csv(f\"vis/l{l}_result.csv\")\n",
    "    #result_df.iloc[:, 1:] = result_df.iloc[:, 1:].map(lambda x: 1 if x >= threshold else 0)\n",
    "    result_df['layer'] = l\n",
    "    \n",
    "    all_results_df.append(result_df)\n",
    "\n",
    "all_results_df = pd.concat(all_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df['Backward'] = (all_results_df['shared_bwd_top_logits'] + all_results_df['shared_bwd_bottom_logits'] + all_results_df['shared_bwd_max_toks']) / .3\n",
    "all_results_df['Forward'] = (all_results_df['shared_fwd_top_logits'] + all_results_df['shared_fwd_bottom_logits'] + all_results_df['shared_fwd_max_toks']) / .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x540 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = all_results_df[['layer', 'Forward', 'Backward']].melt(id_vars='layer', var_name='Transfer', value_name='Transferability')\n",
    "\n",
    "plt.figure(figsize=(7.5, 4.5), dpi=120)\n",
    "sns.set_theme()\n",
    "ax = sns.barplot(\n",
    "    data=plot_df.groupby(['layer', 'Transfer']).mean(),\n",
    "    x='layer',\n",
    "    y='Transferability',\n",
    "    hue='Transfer',\n",
    "    hue_order=['Forward', 'Backward'],\n",
    "    palette=palette_duo,\n",
    ")\n",
    "\n",
    "ax.title.set_fontsize(13)\n",
    "ax.xaxis.label.set_fontsize(10)\n",
    "ax.yaxis.label.set_fontsize(10)\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax.xaxis.labelpad = 10\n",
    "ax.yaxis.labelpad = 10\n",
    "\n",
    "# Set title and move legend out of the plot\n",
    "plt.title(\"Feature Transferability\")\n",
    "plt.xlabel(\"Layer\")\n",
    "# make y axis label in %\n",
    "plt.ylabel(\"Transferability (%)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "sns.move_legend(ax, \"lower center\", bbox_to_anchor=(.5, -0.32), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/f_transfer.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Literal, NamedTuple, Callable\n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "\n",
    "class SaeReconstructionCache(NamedTuple):\n",
    "    sae_in: torch.Tensor\n",
    "    feature_acts: torch.Tensor\n",
    "    sae_out: torch.Tensor\n",
    "    sae_error: torch.Tensor\n",
    "\n",
    "\n",
    "def track_grad(tensor: torch.Tensor) -> None:\n",
    "    \"\"\"wrapper around requires_grad and retain_grad\"\"\"\n",
    "    tensor.requires_grad_(True)\n",
    "    tensor.retain_grad()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ApplySaesAndRunOutput:\n",
    "    model_output: torch.Tensor\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    sae_activations: dict[str, SaeReconstructionCache]\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        \"\"\"Helper to zero grad all tensors in this object.\"\"\"\n",
    "        self.model_output.grad = None\n",
    "        for act in self.model_activations.values():\n",
    "            act.grad = None\n",
    "        for cache in self.sae_activations.values():\n",
    "            cache.sae_in.grad = None\n",
    "            cache.feature_acts.grad = None\n",
    "            cache.sae_out.grad = None\n",
    "            cache.sae_error.grad = None\n",
    "\n",
    "\n",
    "def apply_saes_and_run(\n",
    "    model: HookedTransformer,\n",
    "    saes: dict[str, SAE],\n",
    "    input: Any,\n",
    "    include_error_term: bool = True,\n",
    "    track_model_hooks: list[str] | None = None,\n",
    "    return_type: Literal[\"logits\", \"loss\"] = \"logits\",\n",
    "    track_grads: bool = False,\n",
    ") -> ApplySaesAndRunOutput:\n",
    "    \"\"\"\n",
    "    Apply the SAEs to the model at the specific hook points, and run the model.\n",
    "    By default, this will include a SAE error term which guarantees that the SAE\n",
    "    will not affect model output. This function is designed to work correctly with\n",
    "    backprop as well, so it can be used for gradient-based feature attribution.\n",
    "\n",
    "    Args:\n",
    "        model: the model to run\n",
    "        saes: the SAEs to apply\n",
    "        input: the input to the model\n",
    "        include_error_term: whether to include the SAE error term to ensure the SAE doesn't affect model output. Default True\n",
    "        track_model_hooks: a list of hook points to record the activations and gradients. Default None\n",
    "        return_type: this is passed to the model.run_with_hooks function. Default \"logits\"\n",
    "        track_grads: whether to track gradients. Default False\n",
    "    \"\"\"\n",
    "\n",
    "    fwd_hooks = []\n",
    "    bwd_hooks = []\n",
    "\n",
    "    sae_activations: dict[str, SaeReconstructionCache] = {}\n",
    "    model_activations: dict[str, torch.Tensor] = {}\n",
    "\n",
    "    # this hook just track the SAE input, output, features, and error. If `track_grads=True`, it also ensures\n",
    "    # that requires_grad is set to True and retain_grad is called for intermediate values.\n",
    "    def reconstruction_hook(sae_in: torch.Tensor, hook: HookPoint, hook_point: str):  # noqa: ARG001\n",
    "        sae = saes[hook_point]\n",
    "        feature_acts = sae.encode(sae_in)\n",
    "        sae_out = sae.decode(feature_acts)\n",
    "        sae_error = (sae_in - sae_out).detach().clone()\n",
    "        if track_grads:\n",
    "            track_grad(sae_error)\n",
    "            track_grad(sae_out)\n",
    "            track_grad(feature_acts)\n",
    "            track_grad(sae_in)\n",
    "        sae_activations[hook_point] = SaeReconstructionCache(\n",
    "            sae_in=sae_in,\n",
    "            feature_acts=feature_acts,\n",
    "            sae_out=sae_out,\n",
    "            sae_error=sae_error,\n",
    "        )\n",
    "\n",
    "        if include_error_term:\n",
    "            return sae_out + sae_error\n",
    "        return sae_out\n",
    "\n",
    "    def sae_bwd_hook(output_grads: torch.Tensor, hook: HookPoint):  # noqa: ARG001\n",
    "        # this just passes the output grads to the input, so the SAE gets the same grads despite the error term hackery\n",
    "        return (output_grads,)\n",
    "\n",
    "    # this hook just records model activations, and ensures that intermediate activations have gradient tracking turned on if needed\n",
    "    def tracking_hook(hook_input: torch.Tensor, hook: HookPoint, hook_point: str):  # noqa: ARG001\n",
    "        model_activations[hook_point] = hook_input\n",
    "        if track_grads:\n",
    "            track_grad(hook_input)\n",
    "        return hook_input\n",
    "\n",
    "    for hook_point in saes.keys():\n",
    "        fwd_hooks.append(\n",
    "            (hook_point, partial(reconstruction_hook, hook_point=hook_point))\n",
    "        )\n",
    "        bwd_hooks.append((hook_point, sae_bwd_hook))\n",
    "    for hook_point in track_model_hooks or []:\n",
    "        fwd_hooks.append((hook_point, partial(tracking_hook, hook_point=hook_point)))\n",
    "\n",
    "    # now, just run the model while applying the hooks\n",
    "    with model.hooks(fwd_hooks=fwd_hooks, bwd_hooks=bwd_hooks):\n",
    "        model_output = model(input, return_type=return_type)\n",
    "\n",
    "    return ApplySaesAndRunOutput(\n",
    "        model_output=model_output,\n",
    "        model_activations=model_activations,\n",
    "        sae_activations=sae_activations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Literal, NamedTuple\n",
    "\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import HookedSAETransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "@dataclass\n",
    "class AttributionGrads:\n",
    "    metric: torch.Tensor\n",
    "    model_output: torch.Tensor\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    sae_activations: dict[str, SaeReconstructionCache]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Attribution:\n",
    "    model_attributions: dict[str, torch.Tensor]\n",
    "    model_activations: dict[str, torch.Tensor]\n",
    "    model_grads: dict[str, torch.Tensor]\n",
    "    sae_feature_attributions: dict[str, torch.Tensor]\n",
    "    sae_feature_activations: dict[str, torch.Tensor]\n",
    "    sae_feature_grads: dict[str, torch.Tensor]\n",
    "    sae_errors_attribution_proportion: dict[str, float]\n",
    "\n",
    "\n",
    "def calculate_attribution_grads(\n",
    "    model: HookedSAETransformer,\n",
    "    prompt: str,\n",
    "    metric_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    track_hook_points: list[str] | None = None,\n",
    "    include_saes: dict[str, SAE] | None = None,\n",
    "    return_logits: bool = True,\n",
    "    include_error_term: bool = True,\n",
    ") -> AttributionGrads:\n",
    "    \"\"\"\n",
    "    Wrapper around apply_saes_and_run that calculates gradients wrt to the metric_fn.\n",
    "    Tracks grads for both SAE feature and model neurons, and returns them in a structured format.\n",
    "    \"\"\"\n",
    "    output = apply_saes_and_run(\n",
    "        model,\n",
    "        saes=include_saes or {},\n",
    "        input=prompt,\n",
    "        return_type=\"logits\" if return_logits else \"loss\",\n",
    "        track_model_hooks=track_hook_points,\n",
    "        include_error_term=include_error_term,\n",
    "        track_grads=True,\n",
    "    )\n",
    "    metric = metric_fn(output.model_output)\n",
    "    output.zero_grad()\n",
    "    metric.backward()\n",
    "    return AttributionGrads(\n",
    "        metric=metric,\n",
    "        model_output=output.model_output,\n",
    "        model_activations=output.model_activations,\n",
    "        sae_activations=output.sae_activations,\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_feature_attribution(\n",
    "    model: HookedSAETransformer,\n",
    "    input: Any,\n",
    "    metric_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    track_hook_points: list[str] | None = None,\n",
    "    include_saes: dict[str, SAE] | None = None,\n",
    "    return_logits: bool = True,\n",
    "    include_error_term: bool = True,\n",
    ") -> Attribution:\n",
    "    \"\"\"\n",
    "    Calculate feature attribution for SAE features and model neurons following\n",
    "    the procedure in https://transformer-circuits.pub/2024/march-update/index.html#feature-heads.\n",
    "    This include the SAE error term by default, so inserting the SAE into the calculation is\n",
    "    guaranteed to not affect the model output. This can be disabled by setting `include_error_term=False`.\n",
    "\n",
    "    Args:\n",
    "        model: The model to calculate feature attribution for.\n",
    "        input: The input to the model.\n",
    "        metric_fn: A function that takes the model output and returns a scalar metric.\n",
    "        track_hook_points: A list of model hook points to track activations for, if desired\n",
    "        include_saes: A dictionary of SAEs to include in the calculation. The key is the hook point to apply the SAE to.\n",
    "        return_logits: Whether to return the model logits or loss. This is passed to TLens, so should match whatever the metric_fn expects (probably logits)\n",
    "        include_error_term: Whether to include the SAE error term in the calculation. This is recommended, as it ensures that the SAE will not affecting the model output.\n",
    "    \"\"\"\n",
    "    # first, calculate gradients wrt to the metric_fn.\n",
    "    # these will be multiplied with the activation values to get the attributions\n",
    "    outputs_with_grads = calculate_attribution_grads(\n",
    "        model,\n",
    "        input,\n",
    "        metric_fn,\n",
    "        track_hook_points,\n",
    "        include_saes=include_saes,\n",
    "        return_logits=return_logits,\n",
    "        include_error_term=include_error_term,\n",
    "    )\n",
    "    model_attributions = {}\n",
    "    model_activations = {}\n",
    "    model_grads = {}\n",
    "    sae_feature_attributions = {}\n",
    "    sae_feature_activations = {}\n",
    "    sae_feature_grads = {}\n",
    "    sae_error_proportions = {}\n",
    "    # this code is long, but all it's doing is multiplying the grads by the activations\n",
    "    # and recording grads, acts, and attributions in dictionaries to return to the user\n",
    "    with torch.no_grad():\n",
    "        for name, act in outputs_with_grads.model_activations.items():\n",
    "            assert act.grad is not None\n",
    "            raw_activation = act.detach().clone()\n",
    "            model_attributions[name] = (act.grad * raw_activation).detach().clone()\n",
    "            model_activations[name] = raw_activation\n",
    "            model_grads[name] = act.grad.detach().clone()\n",
    "        for name, act in outputs_with_grads.sae_activations.items():\n",
    "            assert act.feature_acts.grad is not None\n",
    "            assert act.sae_out.grad is not None\n",
    "            raw_activation = act.feature_acts.detach().clone()\n",
    "            sae_feature_attributions[name] = (\n",
    "                (act.feature_acts.grad * raw_activation).detach().clone()\n",
    "            )\n",
    "            sae_feature_activations[name] = raw_activation\n",
    "            sae_feature_grads[name] = act.feature_acts.grad.detach().clone()\n",
    "            if include_error_term:\n",
    "                assert act.sae_error.grad is not None\n",
    "                error_grad_norm = act.sae_error.grad.norm().item()\n",
    "            else:\n",
    "                error_grad_norm = 0\n",
    "            sae_out_norm = act.sae_out.grad.norm().item()\n",
    "            sae_error_proportions[name] = error_grad_norm / (\n",
    "                sae_out_norm + error_grad_norm + EPS\n",
    "            )\n",
    "        return Attribution(\n",
    "            model_attributions=model_attributions,\n",
    "            model_activations=model_activations,\n",
    "            model_grads=model_grads,\n",
    "            sae_feature_attributions=sae_feature_attributions,\n",
    "            sae_feature_activations=sae_feature_activations,\n",
    "            sae_feature_grads=sae_feature_grads,\n",
    "            sae_errors_attribution_proportion=sae_error_proportions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df = pd.read_csv(\"eval/test_attr.csv\")\n",
    "\n",
    "def check_single_token(x):\n",
    "    try:\n",
    "        model.to_single_token(\" \" + x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "attr_df['Correct Single Token'] = attr_df['Correct Answer'].apply(check_single_token)\n",
    "attr_df['Wrong Single Token'] = attr_df['Wrong Answer'].apply(check_single_token)\n",
    "\n",
    "attr_df = attr_df[(attr_df['Correct Single Token']) & (attr_df['Wrong Single Token'])].iloc[:, :-2].drop_duplicates()\n",
    "attr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(idx):\n",
    "    row = attr_df.iloc[idx]\n",
    "    prompt = row['Sentence']\n",
    "    \n",
    "    pos_token = model.tokenizer.encode(\" \" + row['Correct Answer'], add_special_tokens=False)\n",
    "    neg_token = model.tokenizer.encode(\" \" + row['Wrong Answer'], add_special_tokens=False)\n",
    "\n",
    "    return prompt, pos_token, neg_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_feature_to_long_df(sparse_tensor: torch.Tensor) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a sparse tensor to a long format pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(sparse_tensor.detach().cpu().numpy())\n",
    "    df_long = df.melt(ignore_index=False, var_name='column', value_name='value')\n",
    "    df_long.columns = [\"feature\", \"attribution\"]\n",
    "    df_long_nonzero = df_long[df_long['attribution'] != 0]\n",
    "    df_long_nonzero = df_long_nonzero.reset_index().rename(columns={'index': 'position'})\n",
    "    return df_long_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_step = \"100M\"\n",
    "\n",
    "base_fa_scores = []\n",
    "fwd_fa_scores = []\n",
    "bwd_fa_scores = []\n",
    "\n",
    "for l in tqdm(range(1,11)):\n",
    "    \n",
    "    FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{l}\", ckpt_step)\n",
    "    BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{l}\", ckpt_step)\n",
    "    BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{l}\")\n",
    "\n",
    "    fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "    bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "    base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)\n",
    "    \n",
    "    for i in range(attr_df.shape[0]):\n",
    "        prompt, pos_token, neg_token = get_prompt(i)\n",
    "        \n",
    "        def metric_fn(logits: torch.tensor, pos_token: torch.tensor =pos_token, neg_token: torch.Tensor=neg_token) -> torch.Tensor:\n",
    "            return logits[0,-1,pos_token] - logits[0,-1,neg_token]\n",
    "\n",
    "        base_fa = calculate_feature_attribution(\n",
    "            input = prompt,\n",
    "            model = model,\n",
    "            metric_fn = metric_fn,\n",
    "            include_saes={base_sae.cfg.hook_name: base_sae},\n",
    "            include_error_term=True,\n",
    "            return_logits=True,\n",
    "        )\n",
    "\n",
    "        #fwd_fa = calculate_feature_attribution(\n",
    "        #    input = prompt,\n",
    "        #    model = model,\n",
    "        #    metric_fn = metric_fn,\n",
    "        #    include_saes={fwd_sae.cfg.hook_name: fwd_sae},\n",
    "        #    include_error_term=True,\n",
    "        #    return_logits=True,\n",
    "        #)\n",
    "\n",
    "        #bwd_fa = calculate_feature_attribution(\n",
    "        #    input = prompt,\n",
    "        #    model = model,\n",
    "        #    metric_fn = metric_fn,\n",
    "        #    include_saes={bwd_sae.cfg.hook_name: bwd_sae},\n",
    "        #    include_error_term=True,\n",
    "        #    return_logits=True,\n",
    "        #)\n",
    "\n",
    "        base_fa_df = convert_sparse_feature_to_long_df(base_fa.sae_feature_attributions[base_sae.cfg.hook_name][0])\n",
    "        #fwd_fa_df = convert_sparse_feature_to_long_df(fwd_fa.sae_feature_attributions[fwd_sae.cfg.hook_name][0])\n",
    "        #bwd_fa_df = convert_sparse_feature_to_long_df(bwd_fa.sae_feature_attributions[bwd_sae.cfg.hook_name][0])\n",
    "\n",
    "        base_fa_scores.append(base_fa_df['attribution'].max())\n",
    "        #fwd_fa_scores.append(fwd_fa_df['attribution'].max())\n",
    "        #bwd_fa_scores.append(bwd_fa_df['attribution'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer\": np.arange(1,11)[:, None].repeat(len(attr_df)),\n",
    "        \"No transfer\": base_fa_scores,\n",
    "        #\"Forward\": fwd_fa_scores,\n",
    "        #\"Backward\": bwd_fa_scores,\n",
    "    }\n",
    ")\n",
    "\n",
    "scores_df = scores_df.melt(id_vars='Layer', var_name='Transfer', value_name='Max Attribution Score')\n",
    "#scores_df.to_csv(f\"eval/dla_scores_base.csv\", index=False)\n",
    "avg_scores_df = scores_df.groupby(['Layer', 'Transfer']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dla_scores_base = pd.read_csv(\"eval/dla_scores_base.csv\")\n",
    "dla_scores_100 = pd.read_csv(\"eval/dla_scores_100M.csv\")\n",
    "dla_scores_200 = pd.read_csv(\"eval/dla_scores_200M.csv\")\n",
    "dla_scores_300 = pd.read_csv(\"eval/dla_scores_300M.csv\")\n",
    "dla_scores_400 = pd.read_csv(\"eval/dla_scores_400M.csv\")\n",
    "dla_scores_500 = pd.read_csv(\"eval/dla_scores_500M.csv\")\n",
    "\n",
    "dla_scores_100['Checkpoint'] = '100M'\n",
    "dla_scores_200['Checkpoint'] = '200M'\n",
    "dla_scores_300['Checkpoint'] = '300M'\n",
    "dla_scores_400['Checkpoint'] = '400M'\n",
    "dla_scores_500['Checkpoint'] = '500M'\n",
    "\n",
    "dla_scores = pd.concat([dla_scores_100, dla_scores_200, dla_scores_300, dla_scores_400, dla_scores_500])\n",
    "dla_scores = dla_scores[dla_scores['Transfer'] != 'No transfer']\n",
    "avg_scores_df = dla_scores.groupby(['Transfer', 'Checkpoint']).mean().reset_index()\n",
    "avg_base_scores = dla_scores_base.groupby(['Transfer']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=120)\n",
    "sns.set_theme()\n",
    "ax0 = sns.lineplot(\n",
    "    avg_scores_df,\n",
    "    x=\"Checkpoint\",\n",
    "    y=\"Max Attribution Score\",\n",
    "    hue=\"Transfer\",\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    palette=palette_duo,\n",
    "    hue_order=['Forward', 'Backward']\n",
    ")\n",
    "\n",
    "plt.hlines(avg_base_scores['Max Attribution Score'], 0, 4, linestyles='dashed', label='No transfer', color='grey')\n",
    "\n",
    "\n",
    "ax0.title.set_fontsize(13)\n",
    "ax0.xaxis.label.set_fontsize(10)\n",
    "ax0.yaxis.label.set_fontsize(10)\n",
    "ax0.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax0.xaxis.labelpad = 10\n",
    "ax0.yaxis.labelpad = 10\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(\"Direct Logit Attribution Scores\")\n",
    "plt.ylabel(\"Avg. Attribution Score\")\n",
    "# add baseline to legend\n",
    "plt.legend()\n",
    "sns.move_legend(ax0, \"lower center\", bbox_to_anchor=(.5, -0.35), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/dla_scores.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_dla_scores = dla_scores[dla_scores['Transfer'] == 'Forward'].drop(columns=['Transfer'])\n",
    "bwd_dla_scores = dla_scores[dla_scores['Transfer'] == 'Backward'].drop(columns=['Transfer'])\n",
    "\n",
    "avg_fwd_scores = fwd_dla_scores.groupby(['Checkpoint', 'Layer']).mean().reset_index()\n",
    "avg_bwd_scores = bwd_dla_scores.groupby(['Checkpoint', 'Layer']).mean().reset_index()\n",
    "avg_base_scores = dla_scores_base.groupby(['Transfer', 'Layer']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10.5, 4.5), dpi=120)\n",
    "sns.set_theme()\n",
    "ax0 = sns.lineplot(\n",
    "    avg_fwd_scores,\n",
    "    x=\"Checkpoint\",\n",
    "    y=\"Max Attribution Score\",\n",
    "    hue=\"Layer\",\n",
    "    ax=ax[0],\n",
    "    legend=False,\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    palette=palette,\n",
    ")\n",
    "\n",
    "ax1 = sns.lineplot(\n",
    "    avg_bwd_scores,\n",
    "    x=\"Checkpoint\",\n",
    "    y=\"Max Attribution Score\",\n",
    "    hue=\"Layer\",\n",
    "    ax=ax[1],\n",
    "    legend='full',\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "ax[0].set_title(\"Forward Feature Attribution Scores\")\n",
    "ax[0].set_ylabel(\"Attribution Score\")\n",
    "ax[0].set_xlabel(\"Checkpoint\")\n",
    "\n",
    "ax[1].set_title(\"Backward Feature Attribution Scores\")\n",
    "ax[1].set_ylabel(\"Attribution Score\")\n",
    "ax[1].set_xlabel(\"Checkpoint\")\n",
    "\n",
    "for a in ax:\n",
    "    a.title.set_fontsize(13)\n",
    "    a.xaxis.label.set_fontsize(10)\n",
    "    a.yaxis.label.set_fontsize(10)\n",
    "    a.tick_params(axis='both', which='major', labelsize=10)\n",
    "    a.xaxis.labelpad = 10\n",
    "    a.yaxis.labelpad = 10\n",
    "\n",
    "# Adjust legend placement\n",
    "ax[1].legend(title=\"Layer\", bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Apply tight layout to adjust all elements\n",
    "plt.tight_layout()\n",
    "sns.move_legend(ax1, \"lower center\", bbox_to_anchor=(-0.13, -0.35), ncol=5, title=None, frameon=False)\n",
    "plt.savefig(\"img/dla_indv_scores.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_step = \"500M\"\n",
    "\n",
    "base_fwd_similarities = []\n",
    "base_bwd_similarities = []\n",
    "\n",
    "for i in tqdm(range(1, 11)):\n",
    "    BASE_SAE_PATH = os.path.join(SAE_PATH, f\"L{i}\", ckpt_step)\n",
    "    base_sae = SAE.load_from_pretrained(BASE_SAE_PATH).to(device)\n",
    "\n",
    "    base_W_dec = base_sae.W_dec\n",
    "\n",
    "    FWD_SAE_PATH = os.path.join(SAE_PATH, 'forward', f\"L{i}\", ckpt_step)\n",
    "    BWD_SAE_PATH = os.path.join(SAE_PATH, 'backward', f\"L{i}\", ckpt_step)\n",
    "    \n",
    "    fwd_sae = SAE.load_from_pretrained(FWD_SAE_PATH).to(device)\n",
    "    bwd_sae = SAE.load_from_pretrained(BWD_SAE_PATH).to(device)\n",
    "    \n",
    "    fwd_W_dec = fwd_sae.W_dec\n",
    "    bwd_W_dec = bwd_sae.W_dec\n",
    "\n",
    "    base_fwd_sim = (fwd_W_dec @ base_W_dec.T).max(-1).values.mean()\n",
    "    base_bwd_sim = (bwd_W_dec @ base_W_dec.T).max(-1).values.mean()\n",
    "\n",
    "    base_fwd_similarities.append(base_fwd_sim.item())\n",
    "    base_bwd_similarities.append(base_bwd_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=120)\n",
    "sns.set_theme()\n",
    "ax0 = sns.lineplot(\n",
    "    x=np.arange(1, 11),\n",
    "    y=base_fwd_similarities,\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    color=palette[0],\n",
    ")\n",
    "\n",
    "ax1 = sns.lineplot(\n",
    "    x=np.arange(1, 11),\n",
    "    y=base_bwd_similarities,\n",
    "    legend=False,\n",
    "    marker='o',\n",
    "    markersize=6,\n",
    "    color=palette[-1],\n",
    ")\n",
    "\n",
    "ax0.title.set_fontsize(13)\n",
    "ax0.xaxis.label.set_fontsize(10)\n",
    "ax0.yaxis.label.set_fontsize(10)\n",
    "ax0.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax0.xaxis.labelpad = 10\n",
    "ax0.yaxis.labelpad = 10\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title(\"MMCS between Transfer and No transfer SAEs\")\n",
    "plt.ylabel(\"MMCS\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.legend(title=\"Transfer\", labels=[\"Forward\", \"_\", \"Backward\", \"_\"], bbox_to_anchor=(1.03, 1), loc='upper left')\n",
    "plt.ylim(0.59, 0.91)\n",
    "sns.move_legend(ax0, \"lower center\", bbox_to_anchor=(.5, -0.35), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/mmcs_scores.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_df = pd.read_csv(\"eval/human_interp.csv\").fillna(\"y\").drop(\"Feature\", axis=1)\n",
    "hi_df = hi_df.melt(id_vars='Layer', var_name='Transfer', value_name='Human Interpretability Score')\n",
    "hi_df['Human Interpretability Score'] = hi_df['Human Interpretability Score'].apply(lambda x: 0 if x == \"n\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_mask = (hi_df['Layer'] == 0) & (hi_df['Transfer'] == 'Forward')\n",
    "bwd_mask = (hi_df['Layer'] == 11) & (hi_df['Transfer'] == 'Backward')\n",
    "\n",
    "hi_df.loc[fwd_mask, 'Human Interpretability Score'] = 0\n",
    "hi_df.loc[bwd_mask, 'Human Interpretability Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5, 4.5), dpi=120)\n",
    "sns.set_theme()\n",
    "ax = sns.barplot(\n",
    "    hi_df,\n",
    "    x=\"Layer\",\n",
    "    y=\"Human Interpretability Score\",\n",
    "    hue=\"Transfer\",\n",
    "    orient=\"v\",\n",
    "    hue_order=[\"Forward\", \"Backward\", \"No transfer\"],\n",
    "    palette=palette_duo + ['darkgrey'],\n",
    ")\n",
    "\n",
    "ax.title.set_fontsize(13)\n",
    "ax.xaxis.label.set_fontsize(10)\n",
    "ax.yaxis.label.set_fontsize(10)\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax.xaxis.labelpad = 10\n",
    "ax.yaxis.labelpad = 10\n",
    "\n",
    "# Set title and move legend out of the plot\n",
    "plt.title(\"Human Interpretability Scores\")\n",
    "plt.legend()\n",
    "sns.move_legend(ax, \"lower center\", bbox_to_anchor=(.5, -0.32), ncol=3, title=None, frameon=False)\n",
    "plt.savefig(\"img/hi_scores.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
